{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0b47596-f6d9-47ee-9c7b-601faadd3fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "\n",
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "from sklearnex import patch_sklearn  # Intel CPU acceleration for sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2063488c-4bb6-4b47-be15-4174ceaa4b02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">album</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">track</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>...</th>\n",
       "      <th>information</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-11-26 01:49:59</td>\n",
       "      <td>2007-05-22 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>&lt;p&gt;Alec K. Redfearn &amp;amp; The Eyesores: Ellen ...</td>\n",
       "      <td>1300</td>\n",
       "      <td>Alec K. Refearn, Rob Pemberton</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1593</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-Noncommercial-No Derivative Works ...</td>\n",
       "      <td>1299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Queen Of The Wires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:49:57</td>\n",
       "      <td>2009-01-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>&lt;p&gt;A full ensamble of strings, drums, electron...</td>\n",
       "      <td>1304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>839</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-Noncommercial-No Derivative Works ...</td>\n",
       "      <td>725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            album                                                     \\\n",
       "         comments         date_created        date_released engineer   \n",
       "track_id                                                               \n",
       "2               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "5               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "10              0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
       "140             1  2008-11-26 01:49:59  2007-05-22 00:00:00      NaN   \n",
       "141             0  2008-11-26 01:49:57  2009-01-16 00:00:00      NaN   \n",
       "\n",
       "                                                                           \\\n",
       "         favorites  id                                        information   \n",
       "track_id                                                                    \n",
       "2                4   1                                            <p></p>   \n",
       "5                4   1                                            <p></p>   \n",
       "10               4   6                                                NaN   \n",
       "140              1  61  <p>Alec K. Redfearn &amp; The Eyesores: Ellen ...   \n",
       "141              1  60  <p>A full ensamble of strings, drums, electron...   \n",
       "\n",
       "                                                       ...       track  \\\n",
       "         listens                        producer tags  ... information   \n",
       "track_id                                               ...               \n",
       "2           6073                             NaN   []  ...         NaN   \n",
       "5           6073                             NaN   []  ...         NaN   \n",
       "10         47632                             NaN   []  ...         NaN   \n",
       "140         1300  Alec K. Refearn, Rob Pemberton   []  ...         NaN   \n",
       "141         1304                             NaN   []  ...         NaN   \n",
       "\n",
       "                                 \\\n",
       "         interest language_code   \n",
       "track_id                          \n",
       "2            4656            en   \n",
       "5            1933            en   \n",
       "10          54881            en   \n",
       "140          1593            en   \n",
       "141           839            en   \n",
       "\n",
       "                                                                              \\\n",
       "                                                    license listens lyricist   \n",
       "track_id                                                                       \n",
       "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
       "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
       "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
       "140       Attribution-Noncommercial-No Derivative Works ...    1299      NaN   \n",
       "141       Attribution-Noncommercial-No Derivative Works ...     725      NaN   \n",
       "\n",
       "                                                    \n",
       "         number publisher tags               title  \n",
       "track_id                                            \n",
       "2             3       NaN   []                Food  \n",
       "5             6       NaN   []          This World  \n",
       "10            1       NaN   []             Freeway  \n",
       "140           2       NaN   []  Queen Of The Wires  \n",
       "141           4       NaN   []                Ohio  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks = pd.read_csv(\"../data/fma_metadata/tracks.csv\", index_col=0, header=[0,1])\n",
    "tracks = tracks[tracks[\"set\", \"subset\"] == \"small\"]\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "53a86a32-526b-4f93-872d-50ef826b8920",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7994, 3701)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">zcr</th>\n",
       "      <th>track</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">max</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">std</th>\n",
       "      <th>genre_top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_number</th>\n",
       "      <th colspan=\"10\" halign=\"left\">01</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">01</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_pos</th>\n",
       "      <th>pos_01</th>\n",
       "      <th>pos_02</th>\n",
       "      <th>pos_03</th>\n",
       "      <th>pos_04</th>\n",
       "      <th>pos_05</th>\n",
       "      <th>pos_06</th>\n",
       "      <th>pos_07</th>\n",
       "      <th>pos_08</th>\n",
       "      <th>pos_09</th>\n",
       "      <th>pos_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_02</th>\n",
       "      <th>pos_03</th>\n",
       "      <th>pos_04</th>\n",
       "      <th>pos_05</th>\n",
       "      <th>pos_06</th>\n",
       "      <th>pos_07</th>\n",
       "      <th>pos_08</th>\n",
       "      <th>pos_09</th>\n",
       "      <th>pos_10</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.704124</td>\n",
       "      <td>0.670529</td>\n",
       "      <td>0.731929</td>\n",
       "      <td>0.699341</td>\n",
       "      <td>0.558846</td>\n",
       "      <td>0.546863</td>\n",
       "      <td>0.557567</td>\n",
       "      <td>0.506822</td>\n",
       "      <td>0.622437</td>\n",
       "      <td>0.661271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086403</td>\n",
       "      <td>0.061894</td>\n",
       "      <td>0.071970</td>\n",
       "      <td>0.069562</td>\n",
       "      <td>0.050927</td>\n",
       "      <td>0.044658</td>\n",
       "      <td>0.055987</td>\n",
       "      <td>0.066270</td>\n",
       "      <td>0.089225</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.386654</td>\n",
       "      <td>0.396511</td>\n",
       "      <td>0.430391</td>\n",
       "      <td>0.420343</td>\n",
       "      <td>0.459678</td>\n",
       "      <td>0.469663</td>\n",
       "      <td>0.421741</td>\n",
       "      <td>0.440108</td>\n",
       "      <td>0.470912</td>\n",
       "      <td>0.503388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045397</td>\n",
       "      <td>0.051211</td>\n",
       "      <td>0.040011</td>\n",
       "      <td>0.036974</td>\n",
       "      <td>0.029119</td>\n",
       "      <td>0.041461</td>\n",
       "      <td>0.033762</td>\n",
       "      <td>0.072484</td>\n",
       "      <td>0.060742</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.413630</td>\n",
       "      <td>0.393576</td>\n",
       "      <td>0.306028</td>\n",
       "      <td>0.380294</td>\n",
       "      <td>0.286272</td>\n",
       "      <td>0.330367</td>\n",
       "      <td>0.319100</td>\n",
       "      <td>0.301520</td>\n",
       "      <td>0.253617</td>\n",
       "      <td>0.360578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.474108</td>\n",
       "      <td>0.244633</td>\n",
       "      <td>0.398619</td>\n",
       "      <td>0.297416</td>\n",
       "      <td>0.225072</td>\n",
       "      <td>0.398411</td>\n",
       "      <td>0.228512</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>0.398566</td>\n",
       "      <td>0.521293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.033925</td>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.039791</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>0.064145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.519412</td>\n",
       "      <td>0.436285</td>\n",
       "      <td>0.505933</td>\n",
       "      <td>0.355401</td>\n",
       "      <td>0.042728</td>\n",
       "      <td>0.354588</td>\n",
       "      <td>0.371628</td>\n",
       "      <td>0.409198</td>\n",
       "      <td>0.254998</td>\n",
       "      <td>0.441377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015979</td>\n",
       "      <td>0.045776</td>\n",
       "      <td>0.044014</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.030574</td>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>0.026572</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature        chroma_cens                                                    \\\n",
       "statistics             max                                                     \n",
       "feature_number          01                                                     \n",
       "song_pos            pos_01    pos_02    pos_03    pos_04    pos_05    pos_06   \n",
       "track_id                                                                       \n",
       "2                 0.704124  0.670529  0.731929  0.699341  0.558846  0.546863   \n",
       "5                 0.386654  0.396511  0.430391  0.420343  0.459678  0.469663   \n",
       "10                0.413630  0.393576  0.306028  0.380294  0.286272  0.330367   \n",
       "140               0.474108  0.244633  0.398619  0.297416  0.225072  0.398411   \n",
       "141               0.519412  0.436285  0.505933  0.355401  0.042728  0.354588   \n",
       "\n",
       "feature                                                 ...       zcr  \\\n",
       "statistics                                              ...       std   \n",
       "feature_number                                          ...        01   \n",
       "song_pos          pos_07    pos_08    pos_09    pos_10  ...    pos_02   \n",
       "track_id                                                ...             \n",
       "2               0.557567  0.506822  0.622437  0.661271  ...  0.086403   \n",
       "5               0.421741  0.440108  0.470912  0.503388  ...  0.045397   \n",
       "10              0.319100  0.301520  0.253617  0.360578  ...  0.034129   \n",
       "140             0.228512  0.241962  0.398566  0.521293  ...  0.026601   \n",
       "141             0.371628  0.409198  0.254998  0.441377  ...  0.015979   \n",
       "\n",
       "feature                                                                     \\\n",
       "statistics                                                                   \n",
       "feature_number                                                               \n",
       "song_pos          pos_03    pos_04    pos_05    pos_06    pos_07    pos_08   \n",
       "track_id                                                                     \n",
       "2               0.061894  0.071970  0.069562  0.050927  0.044658  0.055987   \n",
       "5               0.051211  0.040011  0.036974  0.029119  0.041461  0.033762   \n",
       "10              0.020003  0.018932  0.016606  0.015600  0.018541  0.018028   \n",
       "140             0.033925  0.023193  0.039791  0.038043  0.039282  0.007803   \n",
       "141             0.045776  0.044014  0.021849  0.030574  0.014621  0.011454   \n",
       "\n",
       "feature                                track  \n",
       "statistics                         genre_top  \n",
       "feature_number                                \n",
       "song_pos          pos_09    pos_10            \n",
       "track_id                                      \n",
       "2               0.066270  0.089225         3  \n",
       "5               0.072484  0.060742         3  \n",
       "10              0.018082  0.014767         6  \n",
       "140             0.014162  0.064145         2  \n",
       "141             0.022677  0.026572         2  \n",
       "\n",
       "[5 rows x 3701 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "features = pd.read_csv(\"../features/fma_features_3sec.csv\", index_col=0, header=[0,1,2,3])\n",
    "# Restrict to small subset\n",
    "features = features.loc[tracks.index]\n",
    "# Join in genre column -- since columns are MultiIndexed, we have to add extra levels\n",
    "label2idx = LabelEncoder().fit(tracks[\"track\", \"genre_top\"])\n",
    "features[\"track\", \"genre_top\", \"\", \"\"] = label2idx.transform(tracks[\"track\", \"genre_top\"])\n",
    "# Remove rows with NaNs (corrupted tracks)\n",
    "features.dropna(inplace=True)\n",
    "print(features.shape)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "90324593-0e35-4587-9896-1ca1fe6bb0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Electronic\n",
      "1     Experimental\n",
      "2             Folk\n",
      "3          Hip-Hop\n",
      "4     Instrumental\n",
      "5    International\n",
      "6              Pop\n",
      "7             Rock\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(label2idx.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7afcd569-eed5-42ce-b9d0-fb7b3f2c4f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6394, 3701) (800, 3701) (800, 3701)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113094/3773691276.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  train = features[tracks[\"set\", \"split\"] == \"training\"]\n",
      "/tmp/ipykernel_113094/3773691276.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  valid = features[tracks[\"set\", \"split\"] == \"validation\"]\n",
      "/tmp/ipykernel_113094/3773691276.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test = features[tracks[\"set\", \"split\"] == \"test\"]\n"
     ]
    }
   ],
   "source": [
    "train = features[tracks[\"set\", \"split\"] == \"training\"]\n",
    "valid = features[tracks[\"set\", \"split\"] == \"validation\"]\n",
    "test = features[tracks[\"set\", \"split\"] == \"test\"]\n",
    "print(train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38423287-accb-4252-aa9c-388a99136537",
   "metadata": {},
   "source": [
    "## PyTorch neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3ba3687b-cc30-4c62-8362-1a5ea7e9559f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AudioFeaturesDataset(Dataset):\n",
    "    def __init__(self, df, chosen_features=slice(None)):\n",
    "        self.df = df\n",
    "        self.chosen_features = chosen_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        X = torch.tensor(self.df.iloc[i][self.chosen_features].values, dtype=torch.float)\n",
    "        y = torch.tensor(self.df.iloc[i][\"track\", \"genre_top\", \"\", \"\"], dtype=torch.long)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "68b0ef0a-a30b-43d9-a689-7d9c9831fd73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6394"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_features = (slice(None), \"mean\", slice(None), slice(None))\n",
    "train_dset = AudioFeaturesDataset(train, chosen_features)\n",
    "valid_dset = AudioFeaturesDataset(valid, chosen_features)\n",
    "test_dset = AudioFeaturesDataset(test, chosen_features)\n",
    "len(train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "34985ee1-9452-4f56-b59d-427ede8db79f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([740])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "799144ef-66aa-41bd-b385-dfee23145ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.1046, 0.2495, 0.3911,  ..., 0.0686, 0.0657, 0.0528],\n",
       "         [0.1734, 0.1492, 0.1476,  ..., 0.0652, 0.0737, 0.0714],\n",
       "         [0.2330, 0.2158, 0.1400,  ..., 0.0387, 0.0488, 0.0859],\n",
       "         ...,\n",
       "         [0.0558, 0.0083, 0.0123,  ..., 0.0706, 0.0665, 0.0582],\n",
       "         [0.0148, 0.0192, 0.0165,  ..., 0.0255, 0.0313, 0.0299],\n",
       "         [0.3062, 0.2247, 0.3782,  ..., 0.0283, 0.0314, 0.0429]]),\n",
       " tensor([7, 7, 1, 6, 7, 4, 4, 5, 2, 7, 0, 5, 7, 7, 2, 0, 4, 1, 5, 7, 4, 1, 2, 3,\n",
       "         2, 6, 0, 4, 3, 7, 6, 7])]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dset, batch_size=32, shuffle=False)\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f7cf2707-5f7d-4bb2-870d-b45a3c7158ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class BasicNetwork(nn.Module):\n",
    "    def __init__(self, in_features, dim_hidden, num_hidden_layers, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_features, dim_hidden)\n",
    "        layers = [nn.ReLU()]\n",
    "        for _ in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(dim_hidden, dim_hidden, dtype=torch.float))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.hidden = nn.ModuleList(layers)\n",
    "        self.output = nn.Linear(dim_hidden, num_classes, dtype=torch.float)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        for layer in self.hidden:\n",
    "            x = layer(x) + x\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d6e79ff4-087d-4c08-b831-4d90ce0b3277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BasicNetwork(\n",
    "    in_features=740,\n",
    "    dim_hidden=100,\n",
    "    num_hidden_layers=5,\n",
    ").to(DEVICE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8a0eca53-0178-4ef8-8b14-24b8d55a1329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "model(X.to(DEVICE)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5689657a-f2a3-4d91-9a71-382effb59ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████▎                | 62/100 [00:03<00:02, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 3.51E-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Axes: xlabel='Learning rate', ylabel='Loss'>, 3.51119173421513e-05)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_loader, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c9dd1dce-aed9-484f-bf22-0c1e5b221836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4738ceaf-9054-48db-a3a8-493da2803d93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train loss 6961.262, accuracy 0.135, F1 0.086 | Valid loss 2899.881, accuracy 0.087, F1 0.064\n",
      "Epoch   1 | Train loss 1795.572, accuracy 0.128, F1 0.119 | Valid loss 1380.149, accuracy 0.124, F1 0.119\n",
      "Epoch   2 | Train loss 1173.381, accuracy 0.177, F1 0.176 | Valid loss 1085.185, accuracy 0.158, F1 0.153\n",
      "Epoch   3 | Train loss  957.114, accuracy 0.190, F1 0.188 | Valid loss  866.345, accuracy 0.182, F1 0.181\n",
      "Epoch   4 | Train loss  765.392, accuracy 0.201, F1 0.200 | Valid loss  670.988, accuracy 0.212, F1 0.208\n",
      "Epoch   5 | Train loss  607.821, accuracy 0.221, F1 0.220 | Valid loss  554.975, accuracy 0.240, F1 0.231\n",
      "Epoch   6 | Train loss  501.979, accuracy 0.236, F1 0.235 | Valid loss  446.895, accuracy 0.251, F1 0.239\n",
      "Epoch   7 | Train loss  401.054, accuracy 0.255, F1 0.255 | Valid loss  357.149, accuracy 0.279, F1 0.275\n",
      "Epoch   8 | Train loss  340.210, accuracy 0.265, F1 0.264 | Valid loss  342.696, accuracy 0.260, F1 0.243\n",
      "Epoch   9 | Train loss  294.330, accuracy 0.277, F1 0.277 | Valid loss  301.324, accuracy 0.295, F1 0.267\n",
      "Epoch  10 | Train loss  262.848, accuracy 0.285, F1 0.285 | Valid loss  256.259, accuracy 0.281, F1 0.271\n",
      "Epoch  11 | Train loss  245.114, accuracy 0.283, F1 0.283 | Valid loss  295.640, accuracy 0.299, F1 0.259\n",
      "Epoch  12 | Train loss  234.550, accuracy 0.289, F1 0.289 | Valid loss  301.095, accuracy 0.328, F1 0.276\n",
      "Epoch  13 | Train loss  220.703, accuracy 0.295, F1 0.295 | Valid loss  288.157, accuracy 0.214, F1 0.205\n",
      "Epoch  14 | Train loss  223.570, accuracy 0.292, F1 0.292 | Valid loss  299.915, accuracy 0.224, F1 0.184\n",
      "Epoch  15 | Train loss  242.872, accuracy 0.293, F1 0.294 | Valid loss  210.162, accuracy 0.310, F1 0.273\n",
      "Epoch  16 | Train loss  204.167, accuracy 0.301, F1 0.301 | Valid loss  283.129, accuracy 0.230, F1 0.200\n",
      "Epoch  17 | Train loss  199.647, accuracy 0.302, F1 0.302 | Valid loss  204.676, accuracy 0.264, F1 0.255\n",
      "Epoch  18 | Train loss  193.369, accuracy 0.305, F1 0.305 | Valid loss  208.553, accuracy 0.254, F1 0.235\n",
      "Epoch  19 | Train loss  198.956, accuracy 0.310, F1 0.310 | Valid loss  246.694, accuracy 0.323, F1 0.282\n",
      "Epoch  20 | Train loss  189.230, accuracy 0.312, F1 0.312 | Valid loss  235.230, accuracy 0.239, F1 0.206\n",
      "Epoch  21 | Train loss  189.465, accuracy 0.310, F1 0.310 | Valid loss  191.047, accuracy 0.287, F1 0.266\n",
      "Epoch  22 | Train loss  167.085, accuracy 0.326, F1 0.326 | Valid loss  159.629, accuracy 0.299, F1 0.276\n",
      "Epoch  23 | Train loss  180.366, accuracy 0.310, F1 0.309 | Valid loss  303.891, accuracy 0.234, F1 0.210\n",
      "Epoch  24 | Train loss  181.681, accuracy 0.306, F1 0.306 | Valid loss  186.614, accuracy 0.265, F1 0.245\n",
      "Epoch  25 | Train loss  151.892, accuracy 0.322, F1 0.322 | Valid loss  216.410, accuracy 0.211, F1 0.163\n",
      "Epoch  26 | Train loss  160.740, accuracy 0.313, F1 0.313 | Valid loss  194.350, accuracy 0.229, F1 0.197\n",
      "Epoch  27 | Train loss  139.569, accuracy 0.327, F1 0.327 | Valid loss  123.059, accuracy 0.315, F1 0.305\n",
      "Epoch  28 | Train loss  148.876, accuracy 0.326, F1 0.326 | Valid loss  138.640, accuracy 0.295, F1 0.273\n",
      "Epoch  29 | Train loss  127.913, accuracy 0.341, F1 0.341 | Valid loss  193.254, accuracy 0.302, F1 0.240\n",
      "Epoch  30 | Train loss  139.344, accuracy 0.327, F1 0.327 | Valid loss  154.684, accuracy 0.339, F1 0.283\n",
      "Epoch  31 | Train loss  125.443, accuracy 0.317, F1 0.317 | Valid loss  164.530, accuracy 0.273, F1 0.225\n",
      "Epoch  32 | Train loss  114.664, accuracy 0.335, F1 0.335 | Valid loss  159.034, accuracy 0.325, F1 0.269\n",
      "Epoch  33 | Train loss  104.948, accuracy 0.341, F1 0.341 | Valid loss  146.030, accuracy 0.301, F1 0.241\n",
      "Epoch  34 | Train loss  108.670, accuracy 0.345, F1 0.344 | Valid loss  176.920, accuracy 0.273, F1 0.247\n",
      "Epoch  35 | Train loss  110.363, accuracy 0.334, F1 0.334 | Valid loss   96.699, accuracy 0.312, F1 0.295\n",
      "Epoch  36 | Train loss   96.523, accuracy 0.341, F1 0.341 | Valid loss  140.145, accuracy 0.274, F1 0.242\n",
      "Epoch  37 | Train loss   95.254, accuracy 0.342, F1 0.342 | Valid loss   91.999, accuracy 0.326, F1 0.303\n",
      "Epoch  38 | Train loss   88.233, accuracy 0.346, F1 0.346 | Valid loss   96.052, accuracy 0.320, F1 0.294\n",
      "Epoch  39 | Train loss   80.990, accuracy 0.360, F1 0.360 | Valid loss  186.632, accuracy 0.176, F1 0.134\n",
      "Epoch  40 | Train loss   82.592, accuracy 0.353, F1 0.354 | Valid loss  118.814, accuracy 0.241, F1 0.207\n",
      "Epoch  41 | Train loss   76.814, accuracy 0.352, F1 0.352 | Valid loss   90.820, accuracy 0.311, F1 0.279\n",
      "Epoch  42 | Train loss   75.187, accuracy 0.352, F1 0.351 | Valid loss   91.369, accuracy 0.311, F1 0.275\n",
      "Epoch  43 | Train loss   78.638, accuracy 0.342, F1 0.342 | Valid loss   94.154, accuracy 0.328, F1 0.261\n",
      "Epoch  44 | Train loss   70.733, accuracy 0.357, F1 0.357 | Valid loss  108.183, accuracy 0.247, F1 0.212\n",
      "Epoch  45 | Train loss   66.867, accuracy 0.360, F1 0.360 | Valid loss   74.559, accuracy 0.326, F1 0.298\n",
      "Epoch  46 | Train loss   62.850, accuracy 0.370, F1 0.369 | Valid loss   67.480, accuracy 0.291, F1 0.272\n",
      "Epoch  47 | Train loss   62.010, accuracy 0.371, F1 0.371 | Valid loss   70.507, accuracy 0.336, F1 0.315\n",
      "Epoch  48 | Train loss   58.692, accuracy 0.363, F1 0.363 | Valid loss   74.969, accuracy 0.321, F1 0.278\n",
      "Epoch  49 | Train loss   59.566, accuracy 0.375, F1 0.375 | Valid loss   68.614, accuracy 0.326, F1 0.298\n",
      "Epoch  50 | Train loss   53.422, accuracy 0.376, F1 0.376 | Valid loss   90.749, accuracy 0.330, F1 0.267\n",
      "Epoch  51 | Train loss   53.030, accuracy 0.371, F1 0.371 | Valid loss   66.849, accuracy 0.299, F1 0.283\n",
      "Epoch  52 | Train loss   49.650, accuracy 0.381, F1 0.381 | Valid loss   59.920, accuracy 0.330, F1 0.292\n",
      "Epoch  53 | Train loss   50.097, accuracy 0.377, F1 0.377 | Valid loss   78.060, accuracy 0.294, F1 0.221\n",
      "Epoch  54 | Train loss   47.622, accuracy 0.382, F1 0.382 | Valid loss   55.226, accuracy 0.356, F1 0.338\n",
      "Epoch  55 | Train loss   42.650, accuracy 0.394, F1 0.394 | Valid loss   60.857, accuracy 0.295, F1 0.269\n",
      "Epoch  56 | Train loss   41.998, accuracy 0.389, F1 0.389 | Valid loss   54.870, accuracy 0.312, F1 0.282\n",
      "Epoch  57 | Train loss   40.969, accuracy 0.388, F1 0.388 | Valid loss   61.771, accuracy 0.330, F1 0.304\n",
      "Epoch  58 | Train loss   41.387, accuracy 0.402, F1 0.402 | Valid loss   54.445, accuracy 0.351, F1 0.314\n",
      "Epoch  59 | Train loss   36.190, accuracy 0.392, F1 0.393 | Valid loss   57.876, accuracy 0.314, F1 0.268\n",
      "Epoch  60 | Train loss   36.461, accuracy 0.397, F1 0.397 | Valid loss   63.420, accuracy 0.294, F1 0.247\n",
      "Epoch  61 | Train loss   41.656, accuracy 0.388, F1 0.388 | Valid loss   48.550, accuracy 0.306, F1 0.283\n",
      "Epoch  62 | Train loss   33.254, accuracy 0.414, F1 0.414 | Valid loss   55.704, accuracy 0.284, F1 0.256\n",
      "Epoch  63 | Train loss   32.533, accuracy 0.413, F1 0.413 | Valid loss   42.984, accuracy 0.324, F1 0.319\n",
      "Epoch  64 | Train loss   29.763, accuracy 0.415, F1 0.415 | Valid loss   45.778, accuracy 0.316, F1 0.284\n",
      "Epoch  65 | Train loss   33.736, accuracy 0.413, F1 0.413 | Valid loss   47.927, accuracy 0.311, F1 0.282\n",
      "Epoch  66 | Train loss   30.364, accuracy 0.411, F1 0.410 | Valid loss   43.610, accuracy 0.314, F1 0.295\n",
      "Epoch  67 | Train loss   27.242, accuracy 0.425, F1 0.425 | Valid loss   52.953, accuracy 0.292, F1 0.278\n",
      "Epoch  68 | Train loss   25.322, accuracy 0.429, F1 0.429 | Valid loss   47.719, accuracy 0.323, F1 0.283\n",
      "Epoch  69 | Train loss   26.382, accuracy 0.431, F1 0.431 | Valid loss   43.224, accuracy 0.334, F1 0.285\n",
      "Epoch  70 | Train loss   24.543, accuracy 0.433, F1 0.433 | Valid loss   40.352, accuracy 0.344, F1 0.319\n",
      "Epoch  71 | Train loss   24.316, accuracy 0.434, F1 0.435 | Valid loss   39.521, accuracy 0.323, F1 0.298\n",
      "Epoch  72 | Train loss   23.253, accuracy 0.434, F1 0.434 | Valid loss   44.218, accuracy 0.286, F1 0.265\n",
      "Epoch  73 | Train loss   21.770, accuracy 0.443, F1 0.443 | Valid loss   38.354, accuracy 0.285, F1 0.279\n",
      "Epoch  74 | Train loss   19.469, accuracy 0.458, F1 0.458 | Valid loss   36.870, accuracy 0.336, F1 0.298\n",
      "Epoch  75 | Train loss   18.705, accuracy 0.459, F1 0.459 | Valid loss   37.739, accuracy 0.339, F1 0.330\n",
      "Epoch  76 | Train loss   18.659, accuracy 0.460, F1 0.460 | Valid loss   35.223, accuracy 0.330, F1 0.310\n",
      "Epoch  77 | Train loss   17.972, accuracy 0.475, F1 0.474 | Valid loss   31.941, accuracy 0.344, F1 0.338\n",
      "Epoch  78 | Train loss   17.243, accuracy 0.471, F1 0.471 | Valid loss   44.205, accuracy 0.304, F1 0.258\n",
      "Epoch  79 | Train loss   17.572, accuracy 0.458, F1 0.458 | Valid loss   33.854, accuracy 0.300, F1 0.286\n",
      "Epoch  80 | Train loss   15.613, accuracy 0.479, F1 0.479 | Valid loss   33.281, accuracy 0.309, F1 0.304\n",
      "Epoch  81 | Train loss   17.151, accuracy 0.459, F1 0.460 | Valid loss   33.390, accuracy 0.325, F1 0.325\n",
      "Epoch  82 | Train loss   15.141, accuracy 0.481, F1 0.480 | Valid loss   34.077, accuracy 0.336, F1 0.313\n",
      "Epoch  83 | Train loss   14.962, accuracy 0.476, F1 0.476 | Valid loss   30.528, accuracy 0.334, F1 0.340\n",
      "Epoch  84 | Train loss   14.506, accuracy 0.481, F1 0.482 | Valid loss   30.055, accuracy 0.351, F1 0.343\n",
      "Epoch  85 | Train loss   13.951, accuracy 0.485, F1 0.485 | Valid loss   31.691, accuracy 0.301, F1 0.307\n",
      "Epoch  86 | Train loss   13.761, accuracy 0.484, F1 0.484 | Valid loss   30.555, accuracy 0.339, F1 0.334\n",
      "Epoch  87 | Train loss   12.409, accuracy 0.502, F1 0.502 | Valid loss   31.083, accuracy 0.321, F1 0.324\n",
      "Epoch  88 | Train loss   12.008, accuracy 0.509, F1 0.509 | Valid loss   29.318, accuracy 0.330, F1 0.329\n",
      "Epoch  89 | Train loss   12.273, accuracy 0.504, F1 0.504 | Valid loss   29.237, accuracy 0.341, F1 0.337\n",
      "Epoch  90 | Train loss   11.829, accuracy 0.508, F1 0.508 | Valid loss   29.719, accuracy 0.336, F1 0.329\n",
      "Epoch  91 | Train loss   11.741, accuracy 0.505, F1 0.504 | Valid loss   28.939, accuracy 0.346, F1 0.344\n",
      "Epoch  92 | Train loss   11.494, accuracy 0.505, F1 0.505 | Valid loss   28.857, accuracy 0.350, F1 0.351\n",
      "Epoch  93 | Train loss   11.304, accuracy 0.519, F1 0.519 | Valid loss   28.819, accuracy 0.345, F1 0.339\n",
      "Epoch  94 | Train loss   11.159, accuracy 0.514, F1 0.514 | Valid loss   29.055, accuracy 0.346, F1 0.342\n",
      "Epoch  95 | Train loss   10.895, accuracy 0.518, F1 0.518 | Valid loss   28.902, accuracy 0.352, F1 0.350\n",
      "Epoch  96 | Train loss   10.792, accuracy 0.520, F1 0.521 | Valid loss   28.708, accuracy 0.349, F1 0.350\n",
      "Epoch  97 | Train loss   10.662, accuracy 0.525, F1 0.525 | Valid loss   28.676, accuracy 0.349, F1 0.348\n",
      "Epoch  98 | Train loss   10.620, accuracy 0.523, F1 0.523 | Valid loss   28.738, accuracy 0.344, F1 0.346\n",
      "Epoch  99 | Train loss   10.569, accuracy 0.523, F1 0.524 | Valid loss   28.720, accuracy 0.344, F1 0.345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "epochs = 100\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, 1e-4, \n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_loader),\n",
    ")\n",
    "labels = np.arange(len(label2idx.classes_))\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss, valid_loss = 0, 0\n",
    "    train_preds = np.array([])\n",
    "    train_true = np.array([])\n",
    "    valid_preds = np.array([])\n",
    "    valid_true = np.array([])\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_logit = model(X.to(DEVICE))\n",
    "        loss = criterion(y_logit, y.to(DEVICE))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        y_pred = y_logit.argmax(dim=1).detach().cpu().numpy()\n",
    "        train_preds = np.hstack([train_preds, y_pred])\n",
    "        train_true = np.hstack([train_true, y.cpu().numpy()])\n",
    "    train_acc = accuracy_score(train_true, train_preds)\n",
    "    train_f1 = f1_score(train_true, train_preds, labels=labels, average=\"macro\")\n",
    "    for X, y in valid_loader:\n",
    "        with torch.inference_mode():\n",
    "            y_logit = model(X.to(DEVICE))\n",
    "            loss = criterion(y_logit, y.to(DEVICE))\n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "        y_pred = y_logit.argmax(dim=1).detach().cpu().numpy()\n",
    "        valid_preds = np.hstack([valid_preds, y_pred])\n",
    "        valid_true = np.hstack([valid_true, y.cpu().numpy()])\n",
    "    valid_acc = accuracy_score(valid_true, valid_preds)\n",
    "    valid_f1 = f1_score(valid_true, valid_preds, labels=labels, average=\"macro\")\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    print(f\"Epoch {i:>3} | Train loss {train_loss:>8.3f}, accuracy {train_acc:>4.3f}, F1 {train_f1:>4.3f} \"\n",
    "          f\"| Valid loss {valid_loss:>8.3f}, accuracy {valid_acc:4.3f}, F1 {valid_f1:>4.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5d66c4b2-1aed-492c-b326-ca049461255d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train loss   10.578, accuracy 0.523, F1 0.523 | Valid loss   28.707, accuracy 0.343, F1 0.343\n",
      "Epoch 101 | Train loss   10.578, accuracy 0.525, F1 0.525 | Valid loss   28.738, accuracy 0.344, F1 0.344\n",
      "Epoch 102 | Train loss   10.572, accuracy 0.523, F1 0.523 | Valid loss   28.732, accuracy 0.340, F1 0.339\n",
      "Epoch 103 | Train loss   10.570, accuracy 0.525, F1 0.524 | Valid loss   28.745, accuracy 0.344, F1 0.345\n",
      "Epoch 104 | Train loss   10.582, accuracy 0.524, F1 0.524 | Valid loss   28.760, accuracy 0.345, F1 0.345\n",
      "Epoch 105 | Train loss   10.570, accuracy 0.525, F1 0.525 | Valid loss   28.726, accuracy 0.345, F1 0.346\n",
      "Epoch 106 | Train loss   10.576, accuracy 0.524, F1 0.524 | Valid loss   28.770, accuracy 0.343, F1 0.345\n",
      "Epoch 107 | Train loss   10.587, accuracy 0.522, F1 0.522 | Valid loss   28.767, accuracy 0.344, F1 0.346\n",
      "Epoch 108 | Train loss   10.586, accuracy 0.523, F1 0.523 | Valid loss   28.771, accuracy 0.344, F1 0.344\n",
      "Epoch 109 | Train loss   10.584, accuracy 0.523, F1 0.523 | Valid loss   28.702, accuracy 0.341, F1 0.343\n",
      "Epoch 110 | Train loss   10.573, accuracy 0.523, F1 0.523 | Valid loss   28.753, accuracy 0.340, F1 0.342\n",
      "Epoch 111 | Train loss   10.573, accuracy 0.522, F1 0.523 | Valid loss   28.694, accuracy 0.347, F1 0.349\n",
      "Epoch 112 | Train loss   10.592, accuracy 0.520, F1 0.520 | Valid loss   28.703, accuracy 0.343, F1 0.343\n",
      "Epoch 113 | Train loss   10.584, accuracy 0.525, F1 0.525 | Valid loss   28.869, accuracy 0.345, F1 0.345\n",
      "Epoch 114 | Train loss   10.620, accuracy 0.523, F1 0.523 | Valid loss   28.689, accuracy 0.343, F1 0.341\n",
      "Epoch 115 | Train loss   10.588, accuracy 0.523, F1 0.523 | Valid loss   28.792, accuracy 0.338, F1 0.340\n",
      "Epoch 116 | Train loss   10.593, accuracy 0.521, F1 0.521 | Valid loss   28.664, accuracy 0.345, F1 0.344\n",
      "Epoch 117 | Train loss   10.596, accuracy 0.522, F1 0.522 | Valid loss   28.658, accuracy 0.340, F1 0.338\n",
      "Epoch 118 | Train loss   10.597, accuracy 0.522, F1 0.522 | Valid loss   28.713, accuracy 0.339, F1 0.339\n",
      "Epoch 119 | Train loss   10.637, accuracy 0.523, F1 0.523 | Valid loss   28.701, accuracy 0.349, F1 0.348\n",
      "Epoch 120 | Train loss   10.637, accuracy 0.520, F1 0.520 | Valid loss   28.594, accuracy 0.344, F1 0.343\n",
      "Epoch 121 | Train loss   10.607, accuracy 0.521, F1 0.521 | Valid loss   28.586, accuracy 0.343, F1 0.343\n",
      "Epoch 122 | Train loss   10.611, accuracy 0.522, F1 0.522 | Valid loss   28.664, accuracy 0.341, F1 0.342\n",
      "Epoch 123 | Train loss   10.621, accuracy 0.524, F1 0.524 | Valid loss   28.729, accuracy 0.349, F1 0.350\n",
      "Epoch 124 | Train loss   10.596, accuracy 0.523, F1 0.522 | Valid loss   28.710, accuracy 0.339, F1 0.339\n",
      "Epoch 125 | Train loss   10.612, accuracy 0.519, F1 0.519 | Valid loss   28.724, accuracy 0.335, F1 0.336\n",
      "Epoch 126 | Train loss   10.627, accuracy 0.518, F1 0.518 | Valid loss   28.875, accuracy 0.335, F1 0.338\n",
      "Epoch 127 | Train loss   10.617, accuracy 0.517, F1 0.517 | Valid loss   28.674, accuracy 0.343, F1 0.343\n",
      "Epoch 128 | Train loss   10.633, accuracy 0.520, F1 0.520 | Valid loss   28.697, accuracy 0.347, F1 0.347\n",
      "Epoch 129 | Train loss   10.638, accuracy 0.518, F1 0.518 | Valid loss   28.524, accuracy 0.345, F1 0.348\n",
      "Epoch 130 | Train loss   10.657, accuracy 0.518, F1 0.518 | Valid loss   28.993, accuracy 0.341, F1 0.340\n",
      "Epoch 131 | Train loss   10.634, accuracy 0.518, F1 0.518 | Valid loss   28.545, accuracy 0.344, F1 0.341\n",
      "Epoch 132 | Train loss   10.632, accuracy 0.520, F1 0.520 | Valid loss   28.550, accuracy 0.341, F1 0.344\n",
      "Epoch 133 | Train loss   10.632, accuracy 0.519, F1 0.519 | Valid loss   28.503, accuracy 0.346, F1 0.346\n",
      "Epoch 134 | Train loss   10.620, accuracy 0.519, F1 0.519 | Valid loss   28.591, accuracy 0.334, F1 0.335\n",
      "Epoch 135 | Train loss   10.633, accuracy 0.517, F1 0.517 | Valid loss   28.641, accuracy 0.347, F1 0.349\n",
      "Epoch 136 | Train loss   10.641, accuracy 0.518, F1 0.518 | Valid loss   28.653, accuracy 0.331, F1 0.334\n",
      "Epoch 137 | Train loss   10.611, accuracy 0.519, F1 0.519 | Valid loss   28.556, accuracy 0.349, F1 0.350\n",
      "Epoch 138 | Train loss   10.584, accuracy 0.518, F1 0.518 | Valid loss   28.674, accuracy 0.344, F1 0.341\n",
      "Epoch 139 | Train loss   10.643, accuracy 0.522, F1 0.522 | Valid loss   28.538, accuracy 0.343, F1 0.344\n",
      "Epoch 140 | Train loss   10.637, accuracy 0.515, F1 0.515 | Valid loss   28.600, accuracy 0.345, F1 0.343\n",
      "Epoch 141 | Train loss   10.611, accuracy 0.519, F1 0.519 | Valid loss   28.621, accuracy 0.330, F1 0.333\n",
      "Epoch 142 | Train loss   10.648, accuracy 0.515, F1 0.515 | Valid loss   28.637, accuracy 0.336, F1 0.335\n",
      "Epoch 143 | Train loss   10.629, accuracy 0.517, F1 0.517 | Valid loss   28.531, accuracy 0.338, F1 0.340\n",
      "Epoch 144 | Train loss   10.567, accuracy 0.518, F1 0.518 | Valid loss   28.403, accuracy 0.339, F1 0.338\n",
      "Epoch 145 | Train loss   10.606, accuracy 0.515, F1 0.515 | Valid loss   28.547, accuracy 0.328, F1 0.329\n",
      "Epoch 146 | Train loss   10.665, accuracy 0.516, F1 0.517 | Valid loss   28.750, accuracy 0.339, F1 0.330\n",
      "Epoch 147 | Train loss   10.551, accuracy 0.517, F1 0.517 | Valid loss   28.405, accuracy 0.345, F1 0.345\n",
      "Epoch 148 | Train loss   10.582, accuracy 0.512, F1 0.512 | Valid loss   28.477, accuracy 0.346, F1 0.346\n",
      "Epoch 149 | Train loss   10.596, accuracy 0.518, F1 0.518 | Valid loss   28.770, accuracy 0.347, F1 0.348\n",
      "Epoch 150 | Train loss   10.509, accuracy 0.511, F1 0.511 | Valid loss   28.314, accuracy 0.346, F1 0.341\n",
      "Epoch 151 | Train loss   10.544, accuracy 0.513, F1 0.513 | Valid loss   28.413, accuracy 0.339, F1 0.337\n",
      "Epoch 152 | Train loss   10.599, accuracy 0.512, F1 0.512 | Valid loss   28.375, accuracy 0.339, F1 0.338\n",
      "Epoch 153 | Train loss   10.508, accuracy 0.517, F1 0.517 | Valid loss   28.739, accuracy 0.340, F1 0.336\n",
      "Epoch 154 | Train loss   10.571, accuracy 0.515, F1 0.515 | Valid loss   28.239, accuracy 0.339, F1 0.337\n",
      "Epoch 155 | Train loss   10.505, accuracy 0.515, F1 0.515 | Valid loss   28.689, accuracy 0.343, F1 0.341\n",
      "Epoch 156 | Train loss   10.561, accuracy 0.514, F1 0.513 | Valid loss   28.276, accuracy 0.333, F1 0.337\n",
      "Epoch 157 | Train loss   10.463, accuracy 0.515, F1 0.515 | Valid loss   28.260, accuracy 0.335, F1 0.334\n",
      "Epoch 158 | Train loss   10.466, accuracy 0.515, F1 0.515 | Valid loss   28.236, accuracy 0.333, F1 0.332\n",
      "Epoch 159 | Train loss   10.507, accuracy 0.512, F1 0.512 | Valid loss   28.376, accuracy 0.330, F1 0.333\n",
      "Epoch 160 | Train loss   10.448, accuracy 0.516, F1 0.516 | Valid loss   28.205, accuracy 0.347, F1 0.349\n",
      "Epoch 161 | Train loss   10.458, accuracy 0.514, F1 0.514 | Valid loss   28.202, accuracy 0.334, F1 0.337\n",
      "Epoch 162 | Train loss   10.415, accuracy 0.515, F1 0.516 | Valid loss   28.755, accuracy 0.339, F1 0.339\n",
      "Epoch 163 | Train loss   10.428, accuracy 0.509, F1 0.509 | Valid loss   27.999, accuracy 0.345, F1 0.345\n",
      "Epoch 164 | Train loss   10.451, accuracy 0.515, F1 0.515 | Valid loss   28.071, accuracy 0.335, F1 0.338\n",
      "Epoch 165 | Train loss   10.413, accuracy 0.510, F1 0.510 | Valid loss   28.648, accuracy 0.346, F1 0.344\n",
      "Epoch 166 | Train loss   10.378, accuracy 0.515, F1 0.515 | Valid loss   28.135, accuracy 0.336, F1 0.337\n",
      "Epoch 167 | Train loss   10.433, accuracy 0.511, F1 0.512 | Valid loss   28.305, accuracy 0.333, F1 0.332\n",
      "Epoch 168 | Train loss   10.381, accuracy 0.516, F1 0.516 | Valid loss   28.229, accuracy 0.341, F1 0.342\n",
      "Epoch 169 | Train loss   10.369, accuracy 0.514, F1 0.514 | Valid loss   28.201, accuracy 0.331, F1 0.333\n",
      "Epoch 170 | Train loss   10.326, accuracy 0.515, F1 0.515 | Valid loss   28.202, accuracy 0.329, F1 0.333\n",
      "Epoch 171 | Train loss   10.284, accuracy 0.516, F1 0.516 | Valid loss   28.022, accuracy 0.339, F1 0.335\n",
      "Epoch 172 | Train loss   10.329, accuracy 0.515, F1 0.515 | Valid loss   28.422, accuracy 0.330, F1 0.324\n",
      "Epoch 173 | Train loss   10.347, accuracy 0.511, F1 0.511 | Valid loss   28.277, accuracy 0.340, F1 0.336\n",
      "Epoch 174 | Train loss   10.306, accuracy 0.514, F1 0.514 | Valid loss   28.258, accuracy 0.328, F1 0.331\n",
      "Epoch 175 | Train loss   10.244, accuracy 0.519, F1 0.519 | Valid loss   27.974, accuracy 0.338, F1 0.337\n",
      "Epoch 176 | Train loss   10.268, accuracy 0.515, F1 0.515 | Valid loss   28.054, accuracy 0.324, F1 0.325\n",
      "Epoch 177 | Train loss   10.275, accuracy 0.515, F1 0.515 | Valid loss   28.376, accuracy 0.336, F1 0.337\n",
      "Epoch 178 | Train loss   10.253, accuracy 0.515, F1 0.516 | Valid loss   28.317, accuracy 0.324, F1 0.328\n",
      "Epoch 179 | Train loss   10.215, accuracy 0.513, F1 0.514 | Valid loss   27.854, accuracy 0.341, F1 0.339\n",
      "Epoch 180 | Train loss   10.230, accuracy 0.510, F1 0.510 | Valid loss   27.971, accuracy 0.345, F1 0.345\n",
      "Epoch 181 | Train loss   10.226, accuracy 0.513, F1 0.513 | Valid loss   28.122, accuracy 0.341, F1 0.340\n",
      "Epoch 182 | Train loss   10.260, accuracy 0.514, F1 0.514 | Valid loss   28.366, accuracy 0.336, F1 0.334\n",
      "Epoch 183 | Train loss   10.229, accuracy 0.517, F1 0.517 | Valid loss   28.432, accuracy 0.340, F1 0.336\n",
      "Epoch 184 | Train loss   10.179, accuracy 0.512, F1 0.512 | Valid loss   28.321, accuracy 0.329, F1 0.332\n",
      "Epoch 185 | Train loss   10.135, accuracy 0.514, F1 0.514 | Valid loss   28.323, accuracy 0.334, F1 0.332\n",
      "Epoch 186 | Train loss   10.126, accuracy 0.513, F1 0.513 | Valid loss   27.650, accuracy 0.334, F1 0.335\n",
      "Epoch 187 | Train loss   10.140, accuracy 0.511, F1 0.511 | Valid loss   27.920, accuracy 0.333, F1 0.331\n",
      "Epoch 188 | Train loss   10.116, accuracy 0.515, F1 0.515 | Valid loss   28.049, accuracy 0.334, F1 0.335\n",
      "Epoch 189 | Train loss   10.106, accuracy 0.513, F1 0.512 | Valid loss   27.665, accuracy 0.343, F1 0.341\n",
      "Epoch 190 | Train loss   10.143, accuracy 0.516, F1 0.516 | Valid loss   27.984, accuracy 0.349, F1 0.346\n",
      "Epoch 191 | Train loss   10.090, accuracy 0.514, F1 0.514 | Valid loss   27.765, accuracy 0.340, F1 0.339\n",
      "Epoch 192 | Train loss   10.072, accuracy 0.513, F1 0.512 | Valid loss   28.309, accuracy 0.321, F1 0.321\n",
      "Epoch 193 | Train loss   10.111, accuracy 0.515, F1 0.515 | Valid loss   28.019, accuracy 0.343, F1 0.339\n",
      "Epoch 194 | Train loss   10.077, accuracy 0.513, F1 0.513 | Valid loss   27.892, accuracy 0.333, F1 0.334\n",
      "Epoch 195 | Train loss   10.002, accuracy 0.517, F1 0.517 | Valid loss   28.119, accuracy 0.338, F1 0.336\n",
      "Epoch 196 | Train loss   10.002, accuracy 0.518, F1 0.518 | Valid loss   27.757, accuracy 0.344, F1 0.343\n",
      "Epoch 197 | Train loss   10.029, accuracy 0.519, F1 0.519 | Valid loss   27.767, accuracy 0.331, F1 0.330\n",
      "Epoch 198 | Train loss   10.011, accuracy 0.515, F1 0.515 | Valid loss   27.939, accuracy 0.344, F1 0.344\n",
      "Epoch 199 | Train loss   10.032, accuracy 0.514, F1 0.514 | Valid loss   27.930, accuracy 0.329, F1 0.330\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-8, weight_decay=1e-2)\n",
    "epochs = 200\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, 1e-6, \n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_loader),\n",
    ")\n",
    "labels = np.arange(len(label2idx.classes_))\n",
    "\n",
    "for i in range(100, epochs):\n",
    "    train_loss, valid_loss = 0, 0\n",
    "    train_preds = np.array([])\n",
    "    train_true = np.array([])\n",
    "    valid_preds = np.array([])\n",
    "    valid_true = np.array([])\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_logit = model(X.to(DEVICE))\n",
    "        loss = criterion(y_logit, y.to(DEVICE))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        y_pred = y_logit.argmax(dim=1).detach().cpu().numpy()\n",
    "        train_preds = np.hstack([train_preds, y_pred])\n",
    "        train_true = np.hstack([train_true, y.cpu().numpy()])\n",
    "    train_acc = accuracy_score(train_true, train_preds)\n",
    "    train_f1 = f1_score(train_true, train_preds, labels=labels, average=\"macro\")\n",
    "    for X, y in valid_loader:\n",
    "        with torch.inference_mode():\n",
    "            y_logit = model(X.to(DEVICE))\n",
    "            loss = criterion(y_logit, y.to(DEVICE))\n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "        y_pred = y_logit.argmax(dim=1).detach().cpu().numpy()\n",
    "        valid_preds = np.hstack([valid_preds, y_pred])\n",
    "        valid_true = np.hstack([valid_true, y.cpu().numpy()])\n",
    "    valid_acc = accuracy_score(valid_true, valid_preds)\n",
    "    valid_f1 = f1_score(valid_true, valid_preds, labels=labels, average=\"macro\")\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    print(f\"Epoch {i:>3} | Train loss {train_loss:>8.3f}, accuracy {train_acc:>4.3f}, F1 {train_f1:>4.3f} \"\n",
    "          f\"| Valid loss {valid_loss:>8.3f}, accuracy {valid_acc:4.3f}, F1 {valid_f1:>4.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4fd88c-1cab-4fc9-a879-07c0bd3b1863",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "932984bc-f8f3-404f-9399-be2c6914bab1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pvk/miniconda3/envs/audiobot/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [22:54:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1713397725960/work/src/learner.cc:742: \n",
      "Parameters: { \"metric\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.88371\n",
      "[1]\tvalidation_0-mlogloss:1.72351\n",
      "[2]\tvalidation_0-mlogloss:1.58785\n",
      "[3]\tvalidation_0-mlogloss:1.47041\n",
      "[4]\tvalidation_0-mlogloss:1.36706\n",
      "[5]\tvalidation_0-mlogloss:1.27495\n",
      "[6]\tvalidation_0-mlogloss:1.19206\n",
      "[7]\tvalidation_0-mlogloss:1.11690\n",
      "[8]\tvalidation_0-mlogloss:1.04831\n",
      "[9]\tvalidation_0-mlogloss:0.98539\n",
      "[10]\tvalidation_0-mlogloss:0.92741\n",
      "[11]\tvalidation_0-mlogloss:0.87380\n",
      "[12]\tvalidation_0-mlogloss:0.82407\n",
      "[13]\tvalidation_0-mlogloss:0.77782\n",
      "[14]\tvalidation_0-mlogloss:0.73469\n",
      "[15]\tvalidation_0-mlogloss:0.69441\n",
      "[16]\tvalidation_0-mlogloss:0.65671\n",
      "[17]\tvalidation_0-mlogloss:0.62137\n",
      "[18]\tvalidation_0-mlogloss:0.58820\n",
      "[19]\tvalidation_0-mlogloss:0.55703\n",
      "[20]\tvalidation_0-mlogloss:0.52771\n",
      "[21]\tvalidation_0-mlogloss:0.50009\n",
      "[22]\tvalidation_0-mlogloss:0.47407\n",
      "[23]\tvalidation_0-mlogloss:0.44952\n",
      "[24]\tvalidation_0-mlogloss:0.42636\n",
      "[25]\tvalidation_0-mlogloss:0.40447\n",
      "[26]\tvalidation_0-mlogloss:0.38380\n",
      "[27]\tvalidation_0-mlogloss:0.36424\n",
      "[28]\tvalidation_0-mlogloss:0.34575\n",
      "[29]\tvalidation_0-mlogloss:0.32825\n",
      "[30]\tvalidation_0-mlogloss:0.31168\n",
      "[31]\tvalidation_0-mlogloss:0.29599\n",
      "[32]\tvalidation_0-mlogloss:0.28113\n",
      "[33]\tvalidation_0-mlogloss:0.26704\n",
      "[34]\tvalidation_0-mlogloss:0.25369\n",
      "[35]\tvalidation_0-mlogloss:0.24103\n",
      "[36]\tvalidation_0-mlogloss:0.22903\n",
      "[37]\tvalidation_0-mlogloss:0.21764\n",
      "[38]\tvalidation_0-mlogloss:0.20684\n",
      "[39]\tvalidation_0-mlogloss:0.19659\n",
      "[40]\tvalidation_0-mlogloss:0.18686\n",
      "[41]\tvalidation_0-mlogloss:0.17763\n",
      "[42]\tvalidation_0-mlogloss:0.16886\n",
      "[43]\tvalidation_0-mlogloss:0.16054\n",
      "[44]\tvalidation_0-mlogloss:0.15264\n",
      "[45]\tvalidation_0-mlogloss:0.14514\n",
      "[46]\tvalidation_0-mlogloss:0.13801\n",
      "[47]\tvalidation_0-mlogloss:0.13124\n",
      "[48]\tvalidation_0-mlogloss:0.12481\n",
      "[49]\tvalidation_0-mlogloss:0.11870\n",
      "[50]\tvalidation_0-mlogloss:0.11290\n",
      "[51]\tvalidation_0-mlogloss:0.10739\n",
      "[52]\tvalidation_0-mlogloss:0.10215\n",
      "[53]\tvalidation_0-mlogloss:0.09717\n",
      "[54]\tvalidation_0-mlogloss:0.09243\n",
      "[55]\tvalidation_0-mlogloss:0.08794\n",
      "[56]\tvalidation_0-mlogloss:0.08366\n",
      "[57]\tvalidation_0-mlogloss:0.07960\n",
      "[58]\tvalidation_0-mlogloss:0.07574\n",
      "[59]\tvalidation_0-mlogloss:0.07207\n",
      "[60]\tvalidation_0-mlogloss:0.06858\n",
      "[61]\tvalidation_0-mlogloss:0.06526\n",
      "[62]\tvalidation_0-mlogloss:0.06211\n",
      "[63]\tvalidation_0-mlogloss:0.05911\n",
      "[64]\tvalidation_0-mlogloss:0.05626\n",
      "[65]\tvalidation_0-mlogloss:0.05355\n",
      "[66]\tvalidation_0-mlogloss:0.05097\n",
      "[67]\tvalidation_0-mlogloss:0.04852\n",
      "[68]\tvalidation_0-mlogloss:0.04619\n",
      "[69]\tvalidation_0-mlogloss:0.04397\n",
      "[70]\tvalidation_0-mlogloss:0.04187\n",
      "[71]\tvalidation_0-mlogloss:0.03986\n",
      "[72]\tvalidation_0-mlogloss:0.03796\n",
      "[73]\tvalidation_0-mlogloss:0.03615\n",
      "[74]\tvalidation_0-mlogloss:0.03442\n",
      "[75]\tvalidation_0-mlogloss:0.03278\n",
      "[76]\tvalidation_0-mlogloss:0.03123\n",
      "[77]\tvalidation_0-mlogloss:0.02974\n",
      "[78]\tvalidation_0-mlogloss:0.02833\n",
      "[79]\tvalidation_0-mlogloss:0.02699\n",
      "[80]\tvalidation_0-mlogloss:0.02572\n",
      "[81]\tvalidation_0-mlogloss:0.02450\n",
      "[82]\tvalidation_0-mlogloss:0.02335\n",
      "[83]\tvalidation_0-mlogloss:0.02225\n",
      "[84]\tvalidation_0-mlogloss:0.02121\n",
      "[85]\tvalidation_0-mlogloss:0.02022\n",
      "[86]\tvalidation_0-mlogloss:0.01927\n",
      "[87]\tvalidation_0-mlogloss:0.01838\n",
      "[88]\tvalidation_0-mlogloss:0.01752\n",
      "[89]\tvalidation_0-mlogloss:0.01671\n",
      "[90]\tvalidation_0-mlogloss:0.01593\n",
      "[91]\tvalidation_0-mlogloss:0.01520\n",
      "[92]\tvalidation_0-mlogloss:0.01450\n",
      "[93]\tvalidation_0-mlogloss:0.01383\n",
      "[94]\tvalidation_0-mlogloss:0.01320\n",
      "[95]\tvalidation_0-mlogloss:0.01260\n",
      "[96]\tvalidation_0-mlogloss:0.01202\n",
      "[97]\tvalidation_0-mlogloss:0.01148\n",
      "[98]\tvalidation_0-mlogloss:0.01096\n",
      "[99]\tvalidation_0-mlogloss:0.01047\n",
      "[100]\tvalidation_0-mlogloss:0.01000\n",
      "[101]\tvalidation_0-mlogloss:0.00955\n",
      "[102]\tvalidation_0-mlogloss:0.00912\n",
      "[103]\tvalidation_0-mlogloss:0.00872\n",
      "[104]\tvalidation_0-mlogloss:0.00833\n",
      "[105]\tvalidation_0-mlogloss:0.00797\n",
      "[106]\tvalidation_0-mlogloss:0.00762\n",
      "[107]\tvalidation_0-mlogloss:0.00729\n",
      "[108]\tvalidation_0-mlogloss:0.00697\n",
      "[109]\tvalidation_0-mlogloss:0.00667\n",
      "[110]\tvalidation_0-mlogloss:0.00638\n",
      "[111]\tvalidation_0-mlogloss:0.00611\n",
      "[112]\tvalidation_0-mlogloss:0.00585\n",
      "[113]\tvalidation_0-mlogloss:0.00560\n",
      "[114]\tvalidation_0-mlogloss:0.00537\n",
      "[115]\tvalidation_0-mlogloss:0.00514\n",
      "[116]\tvalidation_0-mlogloss:0.00493\n",
      "[117]\tvalidation_0-mlogloss:0.00472\n",
      "[118]\tvalidation_0-mlogloss:0.00453\n",
      "[119]\tvalidation_0-mlogloss:0.00435\n",
      "[120]\tvalidation_0-mlogloss:0.00417\n",
      "[121]\tvalidation_0-mlogloss:0.00400\n",
      "[122]\tvalidation_0-mlogloss:0.00384\n",
      "[123]\tvalidation_0-mlogloss:0.00369\n",
      "[124]\tvalidation_0-mlogloss:0.00355\n",
      "[125]\tvalidation_0-mlogloss:0.00342\n",
      "[126]\tvalidation_0-mlogloss:0.00330\n",
      "[127]\tvalidation_0-mlogloss:0.00318\n",
      "[128]\tvalidation_0-mlogloss:0.00307\n",
      "[129]\tvalidation_0-mlogloss:0.00296\n",
      "[130]\tvalidation_0-mlogloss:0.00286\n",
      "[131]\tvalidation_0-mlogloss:0.00276\n",
      "[132]\tvalidation_0-mlogloss:0.00267\n",
      "[133]\tvalidation_0-mlogloss:0.00258\n",
      "[134]\tvalidation_0-mlogloss:0.00249\n",
      "[135]\tvalidation_0-mlogloss:0.00241\n",
      "[136]\tvalidation_0-mlogloss:0.00233\n",
      "[137]\tvalidation_0-mlogloss:0.00226\n",
      "[138]\tvalidation_0-mlogloss:0.00218\n",
      "[139]\tvalidation_0-mlogloss:0.00212\n",
      "[140]\tvalidation_0-mlogloss:0.00205\n",
      "[141]\tvalidation_0-mlogloss:0.00199\n",
      "[142]\tvalidation_0-mlogloss:0.00193\n",
      "[143]\tvalidation_0-mlogloss:0.00188\n",
      "[144]\tvalidation_0-mlogloss:0.00183\n",
      "[145]\tvalidation_0-mlogloss:0.00178\n",
      "[146]\tvalidation_0-mlogloss:0.00174\n",
      "[147]\tvalidation_0-mlogloss:0.00169\n",
      "[148]\tvalidation_0-mlogloss:0.00165\n",
      "[149]\tvalidation_0-mlogloss:0.00161\n",
      "[150]\tvalidation_0-mlogloss:0.00157\n",
      "[151]\tvalidation_0-mlogloss:0.00153\n",
      "[152]\tvalidation_0-mlogloss:0.00150\n",
      "[153]\tvalidation_0-mlogloss:0.00147\n",
      "[154]\tvalidation_0-mlogloss:0.00144\n",
      "[155]\tvalidation_0-mlogloss:0.00141\n",
      "[156]\tvalidation_0-mlogloss:0.00138\n",
      "[157]\tvalidation_0-mlogloss:0.00136\n",
      "[158]\tvalidation_0-mlogloss:0.00133\n",
      "[159]\tvalidation_0-mlogloss:0.00131\n",
      "[160]\tvalidation_0-mlogloss:0.00128\n",
      "[161]\tvalidation_0-mlogloss:0.00126\n",
      "[162]\tvalidation_0-mlogloss:0.00124\n",
      "[163]\tvalidation_0-mlogloss:0.00122\n",
      "[164]\tvalidation_0-mlogloss:0.00120\n",
      "[165]\tvalidation_0-mlogloss:0.00118\n",
      "[166]\tvalidation_0-mlogloss:0.00116\n",
      "[167]\tvalidation_0-mlogloss:0.00114\n",
      "[168]\tvalidation_0-mlogloss:0.00113\n",
      "[169]\tvalidation_0-mlogloss:0.00111\n",
      "[170]\tvalidation_0-mlogloss:0.00110\n",
      "[171]\tvalidation_0-mlogloss:0.00108\n",
      "[172]\tvalidation_0-mlogloss:0.00107\n",
      "[173]\tvalidation_0-mlogloss:0.00106\n",
      "[174]\tvalidation_0-mlogloss:0.00104\n",
      "[175]\tvalidation_0-mlogloss:0.00103\n",
      "[176]\tvalidation_0-mlogloss:0.00102\n",
      "[177]\tvalidation_0-mlogloss:0.00101\n",
      "[178]\tvalidation_0-mlogloss:0.00100\n",
      "[179]\tvalidation_0-mlogloss:0.00100\n",
      "[180]\tvalidation_0-mlogloss:0.00099\n",
      "[181]\tvalidation_0-mlogloss:0.00098\n",
      "[182]\tvalidation_0-mlogloss:0.00097\n",
      "[183]\tvalidation_0-mlogloss:0.00096\n",
      "[184]\tvalidation_0-mlogloss:0.00096\n",
      "[185]\tvalidation_0-mlogloss:0.00096\n",
      "[186]\tvalidation_0-mlogloss:0.00096\n",
      "[187]\tvalidation_0-mlogloss:0.00095\n",
      "[188]\tvalidation_0-mlogloss:0.00095\n",
      "[189]\tvalidation_0-mlogloss:0.00095\n",
      "[190]\tvalidation_0-mlogloss:0.00095\n",
      "[191]\tvalidation_0-mlogloss:0.00094\n",
      "[192]\tvalidation_0-mlogloss:0.00094\n",
      "[193]\tvalidation_0-mlogloss:0.00094\n",
      "[194]\tvalidation_0-mlogloss:0.00094\n",
      "[195]\tvalidation_0-mlogloss:0.00094\n",
      "[196]\tvalidation_0-mlogloss:0.00093\n",
      "[197]\tvalidation_0-mlogloss:0.00093\n",
      "[198]\tvalidation_0-mlogloss:0.00093\n",
      "[199]\tvalidation_0-mlogloss:0.00093\n",
      "[200]\tvalidation_0-mlogloss:0.00093\n",
      "[201]\tvalidation_0-mlogloss:0.00092\n",
      "[202]\tvalidation_0-mlogloss:0.00092\n",
      "[203]\tvalidation_0-mlogloss:0.00092\n",
      "[204]\tvalidation_0-mlogloss:0.00092\n",
      "[205]\tvalidation_0-mlogloss:0.00092\n",
      "[206]\tvalidation_0-mlogloss:0.00091\n",
      "[207]\tvalidation_0-mlogloss:0.00091\n",
      "[208]\tvalidation_0-mlogloss:0.00091\n",
      "[209]\tvalidation_0-mlogloss:0.00091\n",
      "[210]\tvalidation_0-mlogloss:0.00091\n",
      "[211]\tvalidation_0-mlogloss:0.00091\n",
      "[212]\tvalidation_0-mlogloss:0.00090\n",
      "[213]\tvalidation_0-mlogloss:0.00090\n",
      "[214]\tvalidation_0-mlogloss:0.00090\n",
      "[215]\tvalidation_0-mlogloss:0.00090\n",
      "[216]\tvalidation_0-mlogloss:0.00090\n",
      "[217]\tvalidation_0-mlogloss:0.00090\n",
      "[218]\tvalidation_0-mlogloss:0.00090\n",
      "[219]\tvalidation_0-mlogloss:0.00089\n",
      "[220]\tvalidation_0-mlogloss:0.00089\n",
      "[221]\tvalidation_0-mlogloss:0.00089\n",
      "[222]\tvalidation_0-mlogloss:0.00089\n",
      "[223]\tvalidation_0-mlogloss:0.00089\n",
      "[224]\tvalidation_0-mlogloss:0.00089\n",
      "[225]\tvalidation_0-mlogloss:0.00089\n",
      "[226]\tvalidation_0-mlogloss:0.00088\n",
      "[227]\tvalidation_0-mlogloss:0.00088\n",
      "[228]\tvalidation_0-mlogloss:0.00088\n",
      "[229]\tvalidation_0-mlogloss:0.00088\n",
      "[230]\tvalidation_0-mlogloss:0.00088\n",
      "[231]\tvalidation_0-mlogloss:0.00088\n",
      "[232]\tvalidation_0-mlogloss:0.00088\n",
      "[233]\tvalidation_0-mlogloss:0.00088\n",
      "[234]\tvalidation_0-mlogloss:0.00087\n",
      "[235]\tvalidation_0-mlogloss:0.00087\n",
      "[236]\tvalidation_0-mlogloss:0.00087\n",
      "[237]\tvalidation_0-mlogloss:0.00087\n",
      "[238]\tvalidation_0-mlogloss:0.00087\n",
      "[239]\tvalidation_0-mlogloss:0.00087\n",
      "[240]\tvalidation_0-mlogloss:0.00087\n",
      "[241]\tvalidation_0-mlogloss:0.00087\n",
      "[242]\tvalidation_0-mlogloss:0.00086\n",
      "[243]\tvalidation_0-mlogloss:0.00086\n",
      "[244]\tvalidation_0-mlogloss:0.00086\n",
      "[245]\tvalidation_0-mlogloss:0.00086\n",
      "[246]\tvalidation_0-mlogloss:0.00086\n",
      "[247]\tvalidation_0-mlogloss:0.00086\n",
      "[248]\tvalidation_0-mlogloss:0.00086\n",
      "[249]\tvalidation_0-mlogloss:0.00086\n",
      "[250]\tvalidation_0-mlogloss:0.00086\n",
      "[251]\tvalidation_0-mlogloss:0.00086\n",
      "[252]\tvalidation_0-mlogloss:0.00086\n",
      "[253]\tvalidation_0-mlogloss:0.00085\n",
      "[254]\tvalidation_0-mlogloss:0.00085\n",
      "[255]\tvalidation_0-mlogloss:0.00085\n",
      "[256]\tvalidation_0-mlogloss:0.00085\n",
      "[257]\tvalidation_0-mlogloss:0.00085\n",
      "[258]\tvalidation_0-mlogloss:0.00085\n",
      "[259]\tvalidation_0-mlogloss:0.00085\n",
      "[260]\tvalidation_0-mlogloss:0.00085\n",
      "[261]\tvalidation_0-mlogloss:0.00085\n",
      "[262]\tvalidation_0-mlogloss:0.00085\n",
      "[263]\tvalidation_0-mlogloss:0.00085\n",
      "[264]\tvalidation_0-mlogloss:0.00085\n",
      "[265]\tvalidation_0-mlogloss:0.00085\n",
      "[266]\tvalidation_0-mlogloss:0.00084\n",
      "[267]\tvalidation_0-mlogloss:0.00084\n",
      "[268]\tvalidation_0-mlogloss:0.00084\n",
      "[269]\tvalidation_0-mlogloss:0.00084\n",
      "[270]\tvalidation_0-mlogloss:0.00084\n",
      "[271]\tvalidation_0-mlogloss:0.00084\n",
      "[272]\tvalidation_0-mlogloss:0.00084\n",
      "[273]\tvalidation_0-mlogloss:0.00084\n",
      "[274]\tvalidation_0-mlogloss:0.00084\n",
      "[275]\tvalidation_0-mlogloss:0.00084\n",
      "[276]\tvalidation_0-mlogloss:0.00084\n",
      "[277]\tvalidation_0-mlogloss:0.00084\n",
      "[278]\tvalidation_0-mlogloss:0.00084\n",
      "[279]\tvalidation_0-mlogloss:0.00084\n",
      "[280]\tvalidation_0-mlogloss:0.00084\n",
      "[281]\tvalidation_0-mlogloss:0.00084\n",
      "[282]\tvalidation_0-mlogloss:0.00083\n",
      "[283]\tvalidation_0-mlogloss:0.00083\n",
      "[284]\tvalidation_0-mlogloss:0.00083\n",
      "[285]\tvalidation_0-mlogloss:0.00083\n",
      "[286]\tvalidation_0-mlogloss:0.00083\n",
      "[287]\tvalidation_0-mlogloss:0.00083\n",
      "[288]\tvalidation_0-mlogloss:0.00083\n",
      "[289]\tvalidation_0-mlogloss:0.00083\n",
      "[290]\tvalidation_0-mlogloss:0.00083\n",
      "[291]\tvalidation_0-mlogloss:0.00083\n",
      "[292]\tvalidation_0-mlogloss:0.00083\n",
      "[293]\tvalidation_0-mlogloss:0.00083\n",
      "[294]\tvalidation_0-mlogloss:0.00083\n",
      "[295]\tvalidation_0-mlogloss:0.00083\n",
      "[296]\tvalidation_0-mlogloss:0.00083\n",
      "[297]\tvalidation_0-mlogloss:0.00083\n",
      "[298]\tvalidation_0-mlogloss:0.00083\n",
      "[299]\tvalidation_0-mlogloss:0.00083\n",
      "[300]\tvalidation_0-mlogloss:0.00083\n",
      "[301]\tvalidation_0-mlogloss:0.00083\n",
      "[302]\tvalidation_0-mlogloss:0.00082\n",
      "[303]\tvalidation_0-mlogloss:0.00082\n",
      "[304]\tvalidation_0-mlogloss:0.00082\n",
      "[305]\tvalidation_0-mlogloss:0.00082\n",
      "[306]\tvalidation_0-mlogloss:0.00082\n",
      "[307]\tvalidation_0-mlogloss:0.00082\n",
      "[308]\tvalidation_0-mlogloss:0.00082\n",
      "[309]\tvalidation_0-mlogloss:0.00082\n",
      "[310]\tvalidation_0-mlogloss:0.00082\n",
      "[311]\tvalidation_0-mlogloss:0.00082\n",
      "[312]\tvalidation_0-mlogloss:0.00082\n",
      "[313]\tvalidation_0-mlogloss:0.00082\n",
      "[314]\tvalidation_0-mlogloss:0.00082\n",
      "[315]\tvalidation_0-mlogloss:0.00082\n",
      "[316]\tvalidation_0-mlogloss:0.00082\n",
      "[317]\tvalidation_0-mlogloss:0.00082\n",
      "[318]\tvalidation_0-mlogloss:0.00082\n",
      "[319]\tvalidation_0-mlogloss:0.00082\n",
      "[320]\tvalidation_0-mlogloss:0.00082\n",
      "[321]\tvalidation_0-mlogloss:0.00082\n",
      "[322]\tvalidation_0-mlogloss:0.00082\n",
      "[323]\tvalidation_0-mlogloss:0.00082\n",
      "[324]\tvalidation_0-mlogloss:0.00082\n",
      "[325]\tvalidation_0-mlogloss:0.00082\n",
      "[326]\tvalidation_0-mlogloss:0.00082\n",
      "[327]\tvalidation_0-mlogloss:0.00082\n",
      "[328]\tvalidation_0-mlogloss:0.00082\n",
      "[329]\tvalidation_0-mlogloss:0.00082\n",
      "[330]\tvalidation_0-mlogloss:0.00082\n",
      "[331]\tvalidation_0-mlogloss:0.00082\n",
      "[332]\tvalidation_0-mlogloss:0.00081\n",
      "[333]\tvalidation_0-mlogloss:0.00081\n",
      "[334]\tvalidation_0-mlogloss:0.00081\n",
      "[335]\tvalidation_0-mlogloss:0.00081\n",
      "[336]\tvalidation_0-mlogloss:0.00081\n",
      "[337]\tvalidation_0-mlogloss:0.00081\n",
      "[338]\tvalidation_0-mlogloss:0.00081\n",
      "[339]\tvalidation_0-mlogloss:0.00081\n",
      "[340]\tvalidation_0-mlogloss:0.00081\n",
      "[341]\tvalidation_0-mlogloss:0.00081\n",
      "[342]\tvalidation_0-mlogloss:0.00081\n",
      "[343]\tvalidation_0-mlogloss:0.00081\n",
      "[344]\tvalidation_0-mlogloss:0.00081\n",
      "[345]\tvalidation_0-mlogloss:0.00081\n",
      "[346]\tvalidation_0-mlogloss:0.00081\n",
      "[347]\tvalidation_0-mlogloss:0.00081\n",
      "[348]\tvalidation_0-mlogloss:0.00081\n",
      "[349]\tvalidation_0-mlogloss:0.00081\n",
      "[350]\tvalidation_0-mlogloss:0.00081\n",
      "[351]\tvalidation_0-mlogloss:0.00081\n",
      "[352]\tvalidation_0-mlogloss:0.00081\n",
      "[353]\tvalidation_0-mlogloss:0.00081\n",
      "[354]\tvalidation_0-mlogloss:0.00081\n",
      "[355]\tvalidation_0-mlogloss:0.00081\n",
      "[356]\tvalidation_0-mlogloss:0.00081\n",
      "[357]\tvalidation_0-mlogloss:0.00081\n",
      "[358]\tvalidation_0-mlogloss:0.00081\n",
      "[359]\tvalidation_0-mlogloss:0.00081\n",
      "[360]\tvalidation_0-mlogloss:0.00081\n",
      "[361]\tvalidation_0-mlogloss:0.00081\n",
      "[362]\tvalidation_0-mlogloss:0.00081\n",
      "[363]\tvalidation_0-mlogloss:0.00081\n",
      "[364]\tvalidation_0-mlogloss:0.00081\n",
      "[365]\tvalidation_0-mlogloss:0.00081\n",
      "[366]\tvalidation_0-mlogloss:0.00081\n",
      "[367]\tvalidation_0-mlogloss:0.00081\n",
      "[368]\tvalidation_0-mlogloss:0.00081\n",
      "[369]\tvalidation_0-mlogloss:0.00081\n",
      "[370]\tvalidation_0-mlogloss:0.00081\n",
      "[371]\tvalidation_0-mlogloss:0.00081\n",
      "[372]\tvalidation_0-mlogloss:0.00081\n",
      "[373]\tvalidation_0-mlogloss:0.00081\n",
      "[374]\tvalidation_0-mlogloss:0.00081\n",
      "[375]\tvalidation_0-mlogloss:0.00081\n",
      "[376]\tvalidation_0-mlogloss:0.00081\n",
      "[377]\tvalidation_0-mlogloss:0.00081\n",
      "[378]\tvalidation_0-mlogloss:0.00081\n",
      "[379]\tvalidation_0-mlogloss:0.00081\n",
      "[380]\tvalidation_0-mlogloss:0.00080\n",
      "[381]\tvalidation_0-mlogloss:0.00080\n",
      "[382]\tvalidation_0-mlogloss:0.00080\n",
      "[383]\tvalidation_0-mlogloss:0.00080\n",
      "[384]\tvalidation_0-mlogloss:0.00080\n",
      "[385]\tvalidation_0-mlogloss:0.00080\n",
      "[386]\tvalidation_0-mlogloss:0.00080\n",
      "[387]\tvalidation_0-mlogloss:0.00080\n",
      "[388]\tvalidation_0-mlogloss:0.00080\n",
      "[389]\tvalidation_0-mlogloss:0.00080\n",
      "[390]\tvalidation_0-mlogloss:0.00080\n",
      "[391]\tvalidation_0-mlogloss:0.00080\n",
      "[392]\tvalidation_0-mlogloss:0.00080\n",
      "[393]\tvalidation_0-mlogloss:0.00080\n",
      "[394]\tvalidation_0-mlogloss:0.00080\n",
      "[395]\tvalidation_0-mlogloss:0.00080\n",
      "[396]\tvalidation_0-mlogloss:0.00080\n",
      "[397]\tvalidation_0-mlogloss:0.00080\n",
      "[398]\tvalidation_0-mlogloss:0.00080\n",
      "[399]\tvalidation_0-mlogloss:0.00080\n",
      "[400]\tvalidation_0-mlogloss:0.00080\n",
      "[401]\tvalidation_0-mlogloss:0.00080\n",
      "[402]\tvalidation_0-mlogloss:0.00080\n",
      "[403]\tvalidation_0-mlogloss:0.00080\n",
      "[404]\tvalidation_0-mlogloss:0.00080\n",
      "[405]\tvalidation_0-mlogloss:0.00080\n",
      "[406]\tvalidation_0-mlogloss:0.00080\n",
      "[407]\tvalidation_0-mlogloss:0.00080\n",
      "[408]\tvalidation_0-mlogloss:0.00080\n",
      "[409]\tvalidation_0-mlogloss:0.00080\n",
      "[410]\tvalidation_0-mlogloss:0.00080\n",
      "[411]\tvalidation_0-mlogloss:0.00080\n",
      "[412]\tvalidation_0-mlogloss:0.00080\n",
      "[413]\tvalidation_0-mlogloss:0.00080\n",
      "[414]\tvalidation_0-mlogloss:0.00080\n",
      "[415]\tvalidation_0-mlogloss:0.00080\n",
      "[416]\tvalidation_0-mlogloss:0.00080\n",
      "[417]\tvalidation_0-mlogloss:0.00080\n",
      "[418]\tvalidation_0-mlogloss:0.00080\n",
      "[419]\tvalidation_0-mlogloss:0.00080\n",
      "[420]\tvalidation_0-mlogloss:0.00080\n",
      "[421]\tvalidation_0-mlogloss:0.00080\n",
      "[422]\tvalidation_0-mlogloss:0.00080\n",
      "[423]\tvalidation_0-mlogloss:0.00080\n",
      "[424]\tvalidation_0-mlogloss:0.00080\n",
      "[425]\tvalidation_0-mlogloss:0.00080\n",
      "[426]\tvalidation_0-mlogloss:0.00080\n",
      "[427]\tvalidation_0-mlogloss:0.00080\n",
      "[428]\tvalidation_0-mlogloss:0.00080\n",
      "[429]\tvalidation_0-mlogloss:0.00080\n",
      "[430]\tvalidation_0-mlogloss:0.00080\n",
      "[431]\tvalidation_0-mlogloss:0.00080\n",
      "[432]\tvalidation_0-mlogloss:0.00080\n",
      "[433]\tvalidation_0-mlogloss:0.00080\n",
      "[434]\tvalidation_0-mlogloss:0.00080\n",
      "[435]\tvalidation_0-mlogloss:0.00080\n",
      "[436]\tvalidation_0-mlogloss:0.00080\n",
      "[437]\tvalidation_0-mlogloss:0.00080\n",
      "[438]\tvalidation_0-mlogloss:0.00080\n",
      "[439]\tvalidation_0-mlogloss:0.00080\n",
      "[440]\tvalidation_0-mlogloss:0.00080\n",
      "[441]\tvalidation_0-mlogloss:0.00080\n",
      "[442]\tvalidation_0-mlogloss:0.00080\n",
      "[443]\tvalidation_0-mlogloss:0.00080\n",
      "[444]\tvalidation_0-mlogloss:0.00080\n",
      "[445]\tvalidation_0-mlogloss:0.00080\n",
      "[446]\tvalidation_0-mlogloss:0.00079\n",
      "[447]\tvalidation_0-mlogloss:0.00079\n",
      "[448]\tvalidation_0-mlogloss:0.00079\n",
      "[449]\tvalidation_0-mlogloss:0.00079\n",
      "[450]\tvalidation_0-mlogloss:0.00079\n",
      "[451]\tvalidation_0-mlogloss:0.00079\n",
      "[452]\tvalidation_0-mlogloss:0.00079\n",
      "[453]\tvalidation_0-mlogloss:0.00079\n",
      "[454]\tvalidation_0-mlogloss:0.00079\n",
      "[455]\tvalidation_0-mlogloss:0.00079\n",
      "[456]\tvalidation_0-mlogloss:0.00079\n",
      "[457]\tvalidation_0-mlogloss:0.00079\n",
      "[458]\tvalidation_0-mlogloss:0.00079\n",
      "[459]\tvalidation_0-mlogloss:0.00079\n",
      "[460]\tvalidation_0-mlogloss:0.00079\n",
      "[461]\tvalidation_0-mlogloss:0.00079\n",
      "[462]\tvalidation_0-mlogloss:0.00079\n",
      "[463]\tvalidation_0-mlogloss:0.00079\n",
      "[464]\tvalidation_0-mlogloss:0.00079\n",
      "[465]\tvalidation_0-mlogloss:0.00079\n",
      "[466]\tvalidation_0-mlogloss:0.00079\n",
      "[467]\tvalidation_0-mlogloss:0.00079\n",
      "[468]\tvalidation_0-mlogloss:0.00079\n",
      "[469]\tvalidation_0-mlogloss:0.00079\n",
      "[470]\tvalidation_0-mlogloss:0.00079\n",
      "[471]\tvalidation_0-mlogloss:0.00079\n",
      "[472]\tvalidation_0-mlogloss:0.00079\n",
      "[473]\tvalidation_0-mlogloss:0.00079\n",
      "[474]\tvalidation_0-mlogloss:0.00079\n",
      "[475]\tvalidation_0-mlogloss:0.00079\n",
      "[476]\tvalidation_0-mlogloss:0.00079\n",
      "[477]\tvalidation_0-mlogloss:0.00079\n",
      "[478]\tvalidation_0-mlogloss:0.00079\n",
      "[479]\tvalidation_0-mlogloss:0.00079\n",
      "[480]\tvalidation_0-mlogloss:0.00079\n",
      "[481]\tvalidation_0-mlogloss:0.00079\n",
      "[482]\tvalidation_0-mlogloss:0.00079\n",
      "[483]\tvalidation_0-mlogloss:0.00079\n",
      "[484]\tvalidation_0-mlogloss:0.00079\n",
      "[485]\tvalidation_0-mlogloss:0.00079\n",
      "[486]\tvalidation_0-mlogloss:0.00079\n",
      "[487]\tvalidation_0-mlogloss:0.00079\n",
      "[488]\tvalidation_0-mlogloss:0.00079\n",
      "[489]\tvalidation_0-mlogloss:0.00079\n",
      "[490]\tvalidation_0-mlogloss:0.00079\n",
      "[491]\tvalidation_0-mlogloss:0.00079\n",
      "[492]\tvalidation_0-mlogloss:0.00079\n",
      "[493]\tvalidation_0-mlogloss:0.00079\n",
      "[494]\tvalidation_0-mlogloss:0.00079\n",
      "[495]\tvalidation_0-mlogloss:0.00079\n",
      "[496]\tvalidation_0-mlogloss:0.00079\n",
      "[497]\tvalidation_0-mlogloss:0.00079\n",
      "[498]\tvalidation_0-mlogloss:0.00079\n",
      "[499]\tvalidation_0-mlogloss:0.00079\n",
      "[500]\tvalidation_0-mlogloss:0.00079\n",
      "[501]\tvalidation_0-mlogloss:0.00079\n",
      "[502]\tvalidation_0-mlogloss:0.00079\n",
      "[503]\tvalidation_0-mlogloss:0.00079\n",
      "[504]\tvalidation_0-mlogloss:0.00079\n",
      "[505]\tvalidation_0-mlogloss:0.00079\n",
      "[506]\tvalidation_0-mlogloss:0.00079\n",
      "[507]\tvalidation_0-mlogloss:0.00079\n",
      "[508]\tvalidation_0-mlogloss:0.00079\n",
      "[509]\tvalidation_0-mlogloss:0.00079\n",
      "[510]\tvalidation_0-mlogloss:0.00079\n",
      "[511]\tvalidation_0-mlogloss:0.00079\n",
      "[512]\tvalidation_0-mlogloss:0.00079\n",
      "[513]\tvalidation_0-mlogloss:0.00079\n",
      "[514]\tvalidation_0-mlogloss:0.00079\n",
      "[515]\tvalidation_0-mlogloss:0.00079\n",
      "[516]\tvalidation_0-mlogloss:0.00079\n",
      "[517]\tvalidation_0-mlogloss:0.00079\n",
      "[518]\tvalidation_0-mlogloss:0.00079\n",
      "[519]\tvalidation_0-mlogloss:0.00079\n",
      "[520]\tvalidation_0-mlogloss:0.00079\n",
      "[521]\tvalidation_0-mlogloss:0.00079\n",
      "[522]\tvalidation_0-mlogloss:0.00079\n",
      "[523]\tvalidation_0-mlogloss:0.00079\n",
      "[524]\tvalidation_0-mlogloss:0.00079\n",
      "[525]\tvalidation_0-mlogloss:0.00079\n",
      "[526]\tvalidation_0-mlogloss:0.00079\n",
      "[527]\tvalidation_0-mlogloss:0.00079\n",
      "[528]\tvalidation_0-mlogloss:0.00079\n",
      "[529]\tvalidation_0-mlogloss:0.00079\n",
      "[530]\tvalidation_0-mlogloss:0.00079\n",
      "[531]\tvalidation_0-mlogloss:0.00079\n",
      "[532]\tvalidation_0-mlogloss:0.00079\n",
      "[533]\tvalidation_0-mlogloss:0.00079\n",
      "[534]\tvalidation_0-mlogloss:0.00079\n",
      "[535]\tvalidation_0-mlogloss:0.00079\n",
      "[536]\tvalidation_0-mlogloss:0.00079\n",
      "[537]\tvalidation_0-mlogloss:0.00079\n",
      "[538]\tvalidation_0-mlogloss:0.00079\n",
      "[539]\tvalidation_0-mlogloss:0.00079\n",
      "[540]\tvalidation_0-mlogloss:0.00079\n",
      "[541]\tvalidation_0-mlogloss:0.00079\n",
      "[542]\tvalidation_0-mlogloss:0.00079\n",
      "[543]\tvalidation_0-mlogloss:0.00079\n",
      "[544]\tvalidation_0-mlogloss:0.00079\n",
      "[545]\tvalidation_0-mlogloss:0.00079\n",
      "[546]\tvalidation_0-mlogloss:0.00079\n",
      "[547]\tvalidation_0-mlogloss:0.00079\n",
      "[548]\tvalidation_0-mlogloss:0.00079\n",
      "[549]\tvalidation_0-mlogloss:0.00079\n",
      "[550]\tvalidation_0-mlogloss:0.00079\n",
      "[551]\tvalidation_0-mlogloss:0.00079\n",
      "[552]\tvalidation_0-mlogloss:0.00079\n",
      "[553]\tvalidation_0-mlogloss:0.00079\n",
      "[554]\tvalidation_0-mlogloss:0.00079\n",
      "[555]\tvalidation_0-mlogloss:0.00079\n",
      "[556]\tvalidation_0-mlogloss:0.00079\n",
      "[557]\tvalidation_0-mlogloss:0.00079\n",
      "[558]\tvalidation_0-mlogloss:0.00079\n",
      "[559]\tvalidation_0-mlogloss:0.00079\n",
      "[560]\tvalidation_0-mlogloss:0.00079\n",
      "[561]\tvalidation_0-mlogloss:0.00079\n",
      "[562]\tvalidation_0-mlogloss:0.00079\n",
      "[563]\tvalidation_0-mlogloss:0.00079\n",
      "[564]\tvalidation_0-mlogloss:0.00079\n",
      "[565]\tvalidation_0-mlogloss:0.00079\n",
      "[566]\tvalidation_0-mlogloss:0.00079\n",
      "[567]\tvalidation_0-mlogloss:0.00079\n",
      "[568]\tvalidation_0-mlogloss:0.00079\n",
      "[569]\tvalidation_0-mlogloss:0.00079\n",
      "[570]\tvalidation_0-mlogloss:0.00079\n",
      "[571]\tvalidation_0-mlogloss:0.00079\n",
      "[572]\tvalidation_0-mlogloss:0.00079\n",
      "[573]\tvalidation_0-mlogloss:0.00079\n",
      "[574]\tvalidation_0-mlogloss:0.00079\n",
      "[575]\tvalidation_0-mlogloss:0.00079\n",
      "[576]\tvalidation_0-mlogloss:0.00079\n",
      "[577]\tvalidation_0-mlogloss:0.00079\n",
      "[578]\tvalidation_0-mlogloss:0.00079\n",
      "[579]\tvalidation_0-mlogloss:0.00079\n",
      "[580]\tvalidation_0-mlogloss:0.00079\n",
      "[581]\tvalidation_0-mlogloss:0.00079\n",
      "[582]\tvalidation_0-mlogloss:0.00079\n",
      "[583]\tvalidation_0-mlogloss:0.00079\n",
      "[584]\tvalidation_0-mlogloss:0.00079\n",
      "[585]\tvalidation_0-mlogloss:0.00079\n",
      "[586]\tvalidation_0-mlogloss:0.00079\n",
      "[587]\tvalidation_0-mlogloss:0.00079\n",
      "[588]\tvalidation_0-mlogloss:0.00079\n",
      "[589]\tvalidation_0-mlogloss:0.00079\n",
      "[590]\tvalidation_0-mlogloss:0.00079\n",
      "[591]\tvalidation_0-mlogloss:0.00079\n",
      "[592]\tvalidation_0-mlogloss:0.00079\n",
      "[593]\tvalidation_0-mlogloss:0.00079\n",
      "[594]\tvalidation_0-mlogloss:0.00079\n",
      "[595]\tvalidation_0-mlogloss:0.00079\n",
      "[596]\tvalidation_0-mlogloss:0.00079\n",
      "[597]\tvalidation_0-mlogloss:0.00079\n",
      "[598]\tvalidation_0-mlogloss:0.00079\n",
      "[599]\tvalidation_0-mlogloss:0.00079\n",
      "[600]\tvalidation_0-mlogloss:0.00079\n",
      "[601]\tvalidation_0-mlogloss:0.00079\n",
      "[602]\tvalidation_0-mlogloss:0.00079\n",
      "[603]\tvalidation_0-mlogloss:0.00079\n",
      "[604]\tvalidation_0-mlogloss:0.00079\n",
      "[605]\tvalidation_0-mlogloss:0.00079\n",
      "[606]\tvalidation_0-mlogloss:0.00079\n",
      "[607]\tvalidation_0-mlogloss:0.00079\n",
      "[608]\tvalidation_0-mlogloss:0.00079\n",
      "[609]\tvalidation_0-mlogloss:0.00079\n",
      "[610]\tvalidation_0-mlogloss:0.00079\n",
      "[611]\tvalidation_0-mlogloss:0.00079\n",
      "[612]\tvalidation_0-mlogloss:0.00079\n",
      "[613]\tvalidation_0-mlogloss:0.00079\n",
      "[614]\tvalidation_0-mlogloss:0.00079\n",
      "[615]\tvalidation_0-mlogloss:0.00079\n",
      "[616]\tvalidation_0-mlogloss:0.00079\n",
      "[617]\tvalidation_0-mlogloss:0.00079\n",
      "[618]\tvalidation_0-mlogloss:0.00079\n",
      "[619]\tvalidation_0-mlogloss:0.00079\n",
      "[620]\tvalidation_0-mlogloss:0.00079\n",
      "[621]\tvalidation_0-mlogloss:0.00079\n",
      "[622]\tvalidation_0-mlogloss:0.00079\n",
      "[623]\tvalidation_0-mlogloss:0.00079\n",
      "[624]\tvalidation_0-mlogloss:0.00079\n",
      "[625]\tvalidation_0-mlogloss:0.00079\n",
      "[626]\tvalidation_0-mlogloss:0.00079\n",
      "[627]\tvalidation_0-mlogloss:0.00079\n",
      "[628]\tvalidation_0-mlogloss:0.00079\n",
      "[629]\tvalidation_0-mlogloss:0.00079\n",
      "[630]\tvalidation_0-mlogloss:0.00079\n",
      "[631]\tvalidation_0-mlogloss:0.00079\n",
      "[632]\tvalidation_0-mlogloss:0.00079\n",
      "[633]\tvalidation_0-mlogloss:0.00079\n",
      "[634]\tvalidation_0-mlogloss:0.00079\n",
      "[635]\tvalidation_0-mlogloss:0.00079\n",
      "[636]\tvalidation_0-mlogloss:0.00079\n",
      "[637]\tvalidation_0-mlogloss:0.00079\n",
      "[638]\tvalidation_0-mlogloss:0.00079\n",
      "[639]\tvalidation_0-mlogloss:0.00079\n",
      "[640]\tvalidation_0-mlogloss:0.00079\n",
      "[641]\tvalidation_0-mlogloss:0.00079\n",
      "[642]\tvalidation_0-mlogloss:0.00079\n",
      "[643]\tvalidation_0-mlogloss:0.00079\n",
      "[644]\tvalidation_0-mlogloss:0.00079\n",
      "[645]\tvalidation_0-mlogloss:0.00079\n",
      "[646]\tvalidation_0-mlogloss:0.00079\n",
      "[647]\tvalidation_0-mlogloss:0.00079\n",
      "[648]\tvalidation_0-mlogloss:0.00079\n",
      "[649]\tvalidation_0-mlogloss:0.00079\n",
      "[650]\tvalidation_0-mlogloss:0.00079\n",
      "[651]\tvalidation_0-mlogloss:0.00079\n",
      "[652]\tvalidation_0-mlogloss:0.00079\n",
      "[653]\tvalidation_0-mlogloss:0.00079\n",
      "[654]\tvalidation_0-mlogloss:0.00079\n",
      "[655]\tvalidation_0-mlogloss:0.00079\n",
      "[656]\tvalidation_0-mlogloss:0.00079\n",
      "[657]\tvalidation_0-mlogloss:0.00079\n",
      "[658]\tvalidation_0-mlogloss:0.00079\n",
      "[659]\tvalidation_0-mlogloss:0.00079\n",
      "[660]\tvalidation_0-mlogloss:0.00079\n",
      "[661]\tvalidation_0-mlogloss:0.00079\n",
      "[662]\tvalidation_0-mlogloss:0.00079\n",
      "[663]\tvalidation_0-mlogloss:0.00079\n",
      "[664]\tvalidation_0-mlogloss:0.00079\n",
      "[665]\tvalidation_0-mlogloss:0.00079\n",
      "[666]\tvalidation_0-mlogloss:0.00079\n",
      "[667]\tvalidation_0-mlogloss:0.00079\n",
      "[668]\tvalidation_0-mlogloss:0.00079\n",
      "[669]\tvalidation_0-mlogloss:0.00079\n",
      "[670]\tvalidation_0-mlogloss:0.00079\n",
      "[671]\tvalidation_0-mlogloss:0.00079\n",
      "[672]\tvalidation_0-mlogloss:0.00079\n",
      "[673]\tvalidation_0-mlogloss:0.00079\n",
      "[674]\tvalidation_0-mlogloss:0.00079\n",
      "[675]\tvalidation_0-mlogloss:0.00079\n",
      "[676]\tvalidation_0-mlogloss:0.00079\n",
      "[677]\tvalidation_0-mlogloss:0.00079\n",
      "[678]\tvalidation_0-mlogloss:0.00079\n",
      "[679]\tvalidation_0-mlogloss:0.00079\n",
      "[680]\tvalidation_0-mlogloss:0.00079\n",
      "[681]\tvalidation_0-mlogloss:0.00079\n",
      "[682]\tvalidation_0-mlogloss:0.00079\n",
      "[683]\tvalidation_0-mlogloss:0.00079\n",
      "[684]\tvalidation_0-mlogloss:0.00079\n",
      "[685]\tvalidation_0-mlogloss:0.00079\n",
      "[686]\tvalidation_0-mlogloss:0.00079\n",
      "[687]\tvalidation_0-mlogloss:0.00079\n",
      "[688]\tvalidation_0-mlogloss:0.00079\n",
      "[689]\tvalidation_0-mlogloss:0.00079\n",
      "[690]\tvalidation_0-mlogloss:0.00079\n",
      "[691]\tvalidation_0-mlogloss:0.00079\n",
      "[692]\tvalidation_0-mlogloss:0.00079\n",
      "[693]\tvalidation_0-mlogloss:0.00079\n",
      "[694]\tvalidation_0-mlogloss:0.00079\n",
      "[695]\tvalidation_0-mlogloss:0.00079\n",
      "[696]\tvalidation_0-mlogloss:0.00079\n",
      "[697]\tvalidation_0-mlogloss:0.00079\n",
      "[698]\tvalidation_0-mlogloss:0.00079\n",
      "[699]\tvalidation_0-mlogloss:0.00079\n",
      "[700]\tvalidation_0-mlogloss:0.00079\n",
      "[701]\tvalidation_0-mlogloss:0.00079\n",
      "[702]\tvalidation_0-mlogloss:0.00079\n",
      "[703]\tvalidation_0-mlogloss:0.00079\n",
      "[704]\tvalidation_0-mlogloss:0.00079\n",
      "[705]\tvalidation_0-mlogloss:0.00079\n",
      "[706]\tvalidation_0-mlogloss:0.00079\n",
      "[707]\tvalidation_0-mlogloss:0.00079\n",
      "[708]\tvalidation_0-mlogloss:0.00079\n",
      "[709]\tvalidation_0-mlogloss:0.00079\n",
      "[710]\tvalidation_0-mlogloss:0.00079\n",
      "[711]\tvalidation_0-mlogloss:0.00079\n",
      "[712]\tvalidation_0-mlogloss:0.00079\n",
      "[713]\tvalidation_0-mlogloss:0.00079\n",
      "[714]\tvalidation_0-mlogloss:0.00079\n",
      "[715]\tvalidation_0-mlogloss:0.00079\n",
      "[716]\tvalidation_0-mlogloss:0.00079\n",
      "[717]\tvalidation_0-mlogloss:0.00079\n",
      "[718]\tvalidation_0-mlogloss:0.00079\n",
      "[719]\tvalidation_0-mlogloss:0.00079\n",
      "[720]\tvalidation_0-mlogloss:0.00079\n",
      "[721]\tvalidation_0-mlogloss:0.00079\n",
      "[722]\tvalidation_0-mlogloss:0.00079\n",
      "[723]\tvalidation_0-mlogloss:0.00079\n",
      "[724]\tvalidation_0-mlogloss:0.00079\n",
      "[725]\tvalidation_0-mlogloss:0.00079\n",
      "[726]\tvalidation_0-mlogloss:0.00079\n",
      "[727]\tvalidation_0-mlogloss:0.00079\n",
      "[728]\tvalidation_0-mlogloss:0.00079\n",
      "[729]\tvalidation_0-mlogloss:0.00079\n",
      "[730]\tvalidation_0-mlogloss:0.00079\n",
      "[731]\tvalidation_0-mlogloss:0.00079\n",
      "[732]\tvalidation_0-mlogloss:0.00079\n",
      "[733]\tvalidation_0-mlogloss:0.00079\n",
      "[734]\tvalidation_0-mlogloss:0.00079\n",
      "[735]\tvalidation_0-mlogloss:0.00079\n",
      "[736]\tvalidation_0-mlogloss:0.00079\n",
      "[737]\tvalidation_0-mlogloss:0.00079\n",
      "[738]\tvalidation_0-mlogloss:0.00079\n",
      "[739]\tvalidation_0-mlogloss:0.00079\n",
      "[740]\tvalidation_0-mlogloss:0.00079\n",
      "[741]\tvalidation_0-mlogloss:0.00078\n",
      "[742]\tvalidation_0-mlogloss:0.00078\n",
      "[743]\tvalidation_0-mlogloss:0.00078\n",
      "[744]\tvalidation_0-mlogloss:0.00078\n",
      "[745]\tvalidation_0-mlogloss:0.00078\n",
      "[746]\tvalidation_0-mlogloss:0.00078\n",
      "[747]\tvalidation_0-mlogloss:0.00078\n",
      "[748]\tvalidation_0-mlogloss:0.00078\n",
      "[749]\tvalidation_0-mlogloss:0.00078\n",
      "[750]\tvalidation_0-mlogloss:0.00078\n",
      "[751]\tvalidation_0-mlogloss:0.00078\n",
      "[752]\tvalidation_0-mlogloss:0.00078\n",
      "[753]\tvalidation_0-mlogloss:0.00078\n",
      "[754]\tvalidation_0-mlogloss:0.00078\n",
      "[755]\tvalidation_0-mlogloss:0.00078\n",
      "[756]\tvalidation_0-mlogloss:0.00078\n",
      "[757]\tvalidation_0-mlogloss:0.00078\n",
      "[758]\tvalidation_0-mlogloss:0.00078\n",
      "[759]\tvalidation_0-mlogloss:0.00078\n",
      "[760]\tvalidation_0-mlogloss:0.00078\n",
      "[761]\tvalidation_0-mlogloss:0.00078\n",
      "[762]\tvalidation_0-mlogloss:0.00078\n",
      "[763]\tvalidation_0-mlogloss:0.00078\n",
      "[764]\tvalidation_0-mlogloss:0.00078\n",
      "[765]\tvalidation_0-mlogloss:0.00078\n",
      "[766]\tvalidation_0-mlogloss:0.00078\n",
      "[767]\tvalidation_0-mlogloss:0.00078\n",
      "[768]\tvalidation_0-mlogloss:0.00078\n",
      "[769]\tvalidation_0-mlogloss:0.00078\n",
      "[770]\tvalidation_0-mlogloss:0.00078\n",
      "[771]\tvalidation_0-mlogloss:0.00078\n",
      "[772]\tvalidation_0-mlogloss:0.00078\n",
      "[773]\tvalidation_0-mlogloss:0.00078\n",
      "[774]\tvalidation_0-mlogloss:0.00078\n",
      "[775]\tvalidation_0-mlogloss:0.00078\n",
      "[776]\tvalidation_0-mlogloss:0.00078\n",
      "[777]\tvalidation_0-mlogloss:0.00078\n",
      "[778]\tvalidation_0-mlogloss:0.00078\n",
      "[779]\tvalidation_0-mlogloss:0.00078\n",
      "[780]\tvalidation_0-mlogloss:0.00078\n",
      "[781]\tvalidation_0-mlogloss:0.00078\n",
      "[782]\tvalidation_0-mlogloss:0.00078\n",
      "[783]\tvalidation_0-mlogloss:0.00078\n",
      "[784]\tvalidation_0-mlogloss:0.00078\n",
      "[785]\tvalidation_0-mlogloss:0.00078\n",
      "[786]\tvalidation_0-mlogloss:0.00078\n",
      "[787]\tvalidation_0-mlogloss:0.00078\n",
      "[788]\tvalidation_0-mlogloss:0.00078\n",
      "[789]\tvalidation_0-mlogloss:0.00078\n",
      "[790]\tvalidation_0-mlogloss:0.00078\n",
      "[791]\tvalidation_0-mlogloss:0.00078\n",
      "[792]\tvalidation_0-mlogloss:0.00078\n",
      "[793]\tvalidation_0-mlogloss:0.00078\n",
      "[794]\tvalidation_0-mlogloss:0.00078\n",
      "[795]\tvalidation_0-mlogloss:0.00078\n",
      "[796]\tvalidation_0-mlogloss:0.00078\n",
      "[797]\tvalidation_0-mlogloss:0.00078\n",
      "[798]\tvalidation_0-mlogloss:0.00078\n",
      "[799]\tvalidation_0-mlogloss:0.00078\n",
      "[800]\tvalidation_0-mlogloss:0.00078\n",
      "[801]\tvalidation_0-mlogloss:0.00078\n",
      "[802]\tvalidation_0-mlogloss:0.00078\n",
      "[803]\tvalidation_0-mlogloss:0.00078\n",
      "[804]\tvalidation_0-mlogloss:0.00078\n",
      "[805]\tvalidation_0-mlogloss:0.00078\n",
      "[806]\tvalidation_0-mlogloss:0.00078\n",
      "[807]\tvalidation_0-mlogloss:0.00078\n",
      "[808]\tvalidation_0-mlogloss:0.00078\n",
      "[809]\tvalidation_0-mlogloss:0.00078\n",
      "[810]\tvalidation_0-mlogloss:0.00078\n",
      "[811]\tvalidation_0-mlogloss:0.00078\n",
      "[812]\tvalidation_0-mlogloss:0.00078\n",
      "[813]\tvalidation_0-mlogloss:0.00078\n",
      "[814]\tvalidation_0-mlogloss:0.00078\n",
      "[815]\tvalidation_0-mlogloss:0.00078\n",
      "[816]\tvalidation_0-mlogloss:0.00078\n",
      "[817]\tvalidation_0-mlogloss:0.00078\n",
      "[818]\tvalidation_0-mlogloss:0.00078\n",
      "[819]\tvalidation_0-mlogloss:0.00078\n",
      "[820]\tvalidation_0-mlogloss:0.00078\n",
      "[821]\tvalidation_0-mlogloss:0.00078\n",
      "[822]\tvalidation_0-mlogloss:0.00078\n",
      "[823]\tvalidation_0-mlogloss:0.00078\n",
      "[824]\tvalidation_0-mlogloss:0.00078\n",
      "[825]\tvalidation_0-mlogloss:0.00078\n",
      "[826]\tvalidation_0-mlogloss:0.00078\n",
      "[827]\tvalidation_0-mlogloss:0.00078\n",
      "[828]\tvalidation_0-mlogloss:0.00078\n",
      "[829]\tvalidation_0-mlogloss:0.00078\n",
      "[830]\tvalidation_0-mlogloss:0.00078\n",
      "[831]\tvalidation_0-mlogloss:0.00078\n",
      "[832]\tvalidation_0-mlogloss:0.00078\n",
      "[833]\tvalidation_0-mlogloss:0.00078\n",
      "[834]\tvalidation_0-mlogloss:0.00078\n",
      "[835]\tvalidation_0-mlogloss:0.00078\n",
      "[836]\tvalidation_0-mlogloss:0.00078\n",
      "[837]\tvalidation_0-mlogloss:0.00078\n",
      "[838]\tvalidation_0-mlogloss:0.00078\n",
      "[839]\tvalidation_0-mlogloss:0.00078\n",
      "[840]\tvalidation_0-mlogloss:0.00078\n",
      "[841]\tvalidation_0-mlogloss:0.00078\n",
      "[842]\tvalidation_0-mlogloss:0.00078\n",
      "[843]\tvalidation_0-mlogloss:0.00078\n",
      "[844]\tvalidation_0-mlogloss:0.00078\n",
      "[845]\tvalidation_0-mlogloss:0.00078\n",
      "[846]\tvalidation_0-mlogloss:0.00078\n",
      "[847]\tvalidation_0-mlogloss:0.00078\n",
      "[848]\tvalidation_0-mlogloss:0.00078\n",
      "[849]\tvalidation_0-mlogloss:0.00078\n",
      "[850]\tvalidation_0-mlogloss:0.00078\n",
      "[851]\tvalidation_0-mlogloss:0.00078\n",
      "[852]\tvalidation_0-mlogloss:0.00078\n",
      "[853]\tvalidation_0-mlogloss:0.00078\n",
      "[854]\tvalidation_0-mlogloss:0.00078\n",
      "[855]\tvalidation_0-mlogloss:0.00078\n",
      "[856]\tvalidation_0-mlogloss:0.00078\n",
      "[857]\tvalidation_0-mlogloss:0.00078\n",
      "[858]\tvalidation_0-mlogloss:0.00078\n",
      "[859]\tvalidation_0-mlogloss:0.00078\n",
      "[860]\tvalidation_0-mlogloss:0.00078\n",
      "[861]\tvalidation_0-mlogloss:0.00078\n",
      "[862]\tvalidation_0-mlogloss:0.00078\n",
      "[863]\tvalidation_0-mlogloss:0.00078\n",
      "[864]\tvalidation_0-mlogloss:0.00078\n",
      "[865]\tvalidation_0-mlogloss:0.00078\n",
      "[866]\tvalidation_0-mlogloss:0.00078\n",
      "[867]\tvalidation_0-mlogloss:0.00078\n",
      "[868]\tvalidation_0-mlogloss:0.00078\n",
      "[869]\tvalidation_0-mlogloss:0.00078\n",
      "[870]\tvalidation_0-mlogloss:0.00078\n",
      "[871]\tvalidation_0-mlogloss:0.00078\n",
      "[872]\tvalidation_0-mlogloss:0.00078\n",
      "[873]\tvalidation_0-mlogloss:0.00078\n",
      "[874]\tvalidation_0-mlogloss:0.00078\n",
      "[875]\tvalidation_0-mlogloss:0.00078\n",
      "[876]\tvalidation_0-mlogloss:0.00078\n",
      "[877]\tvalidation_0-mlogloss:0.00078\n",
      "[878]\tvalidation_0-mlogloss:0.00078\n",
      "[879]\tvalidation_0-mlogloss:0.00078\n",
      "[880]\tvalidation_0-mlogloss:0.00078\n",
      "[881]\tvalidation_0-mlogloss:0.00078\n",
      "[882]\tvalidation_0-mlogloss:0.00078\n",
      "[883]\tvalidation_0-mlogloss:0.00078\n",
      "[884]\tvalidation_0-mlogloss:0.00078\n",
      "[885]\tvalidation_0-mlogloss:0.00078\n",
      "[886]\tvalidation_0-mlogloss:0.00078\n",
      "[887]\tvalidation_0-mlogloss:0.00078\n",
      "[888]\tvalidation_0-mlogloss:0.00078\n",
      "[889]\tvalidation_0-mlogloss:0.00078\n",
      "[890]\tvalidation_0-mlogloss:0.00078\n",
      "[891]\tvalidation_0-mlogloss:0.00078\n",
      "[892]\tvalidation_0-mlogloss:0.00078\n",
      "[893]\tvalidation_0-mlogloss:0.00078\n",
      "[894]\tvalidation_0-mlogloss:0.00078\n",
      "[895]\tvalidation_0-mlogloss:0.00078\n",
      "[896]\tvalidation_0-mlogloss:0.00078\n",
      "[897]\tvalidation_0-mlogloss:0.00078\n",
      "[898]\tvalidation_0-mlogloss:0.00078\n",
      "[899]\tvalidation_0-mlogloss:0.00078\n",
      "[900]\tvalidation_0-mlogloss:0.00078\n",
      "[901]\tvalidation_0-mlogloss:0.00078\n",
      "[902]\tvalidation_0-mlogloss:0.00078\n",
      "[903]\tvalidation_0-mlogloss:0.00078\n",
      "[904]\tvalidation_0-mlogloss:0.00078\n",
      "[905]\tvalidation_0-mlogloss:0.00078\n",
      "[906]\tvalidation_0-mlogloss:0.00078\n",
      "[907]\tvalidation_0-mlogloss:0.00078\n",
      "[908]\tvalidation_0-mlogloss:0.00078\n",
      "[909]\tvalidation_0-mlogloss:0.00078\n",
      "[910]\tvalidation_0-mlogloss:0.00078\n",
      "[911]\tvalidation_0-mlogloss:0.00078\n",
      "[912]\tvalidation_0-mlogloss:0.00078\n",
      "[913]\tvalidation_0-mlogloss:0.00078\n",
      "[914]\tvalidation_0-mlogloss:0.00078\n",
      "[915]\tvalidation_0-mlogloss:0.00078\n",
      "[916]\tvalidation_0-mlogloss:0.00078\n",
      "[917]\tvalidation_0-mlogloss:0.00078\n",
      "[918]\tvalidation_0-mlogloss:0.00078\n",
      "[919]\tvalidation_0-mlogloss:0.00078\n",
      "[920]\tvalidation_0-mlogloss:0.00078\n",
      "[921]\tvalidation_0-mlogloss:0.00078\n",
      "[922]\tvalidation_0-mlogloss:0.00078\n",
      "[923]\tvalidation_0-mlogloss:0.00078\n",
      "[924]\tvalidation_0-mlogloss:0.00078\n",
      "[925]\tvalidation_0-mlogloss:0.00078\n",
      "[926]\tvalidation_0-mlogloss:0.00078\n",
      "[927]\tvalidation_0-mlogloss:0.00078\n",
      "[928]\tvalidation_0-mlogloss:0.00078\n",
      "[929]\tvalidation_0-mlogloss:0.00078\n",
      "[930]\tvalidation_0-mlogloss:0.00078\n",
      "[931]\tvalidation_0-mlogloss:0.00078\n",
      "[932]\tvalidation_0-mlogloss:0.00078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=20,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              metric=&#x27;mlogloss&#x27;, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=20,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              metric=&#x27;mlogloss&#x27;, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='cuda', early_stopping_rounds=20,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              metric='mlogloss', min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "chosen_features = (slice(None), slice(None), slice(None), slice(None))\n",
    "\n",
    "X_train, y_train = train.loc[:, chosen_features], train.iloc[:, -1]\n",
    "X_valid, y_valid = valid.loc[:, chosen_features], valid.iloc[:, -1]\n",
    "X_test, y_test = test.loc[:, chosen_features], test.iloc[:, -1]\n",
    "\n",
    "X_tt, X_tv, y_tt, y_tv = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=4)\n",
    "\n",
    "model = XGBClassifier(\n",
    "    device=\"cuda\",\n",
    "    max_depth=3,\n",
    "    early_stopping_rounds=20,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    objective=\"multi:softmax\",\n",
    ")\n",
    "\n",
    "model.fit(X_tt, y_tt, eval_set=[(X_tv, y_tv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "336417b4-c85c-4e32-8efa-cbc9815b0f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss    0.001, accuracy 1.000, F1 1.000 | Valid loss    0.001, accuracy 1.000, F1 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "y_train_prob = model.predict_proba(X_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_prob = model.predict_proba(X_valid)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "train_loss = log_loss(y_train, y_train_prob)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, labels=np.arange(len(label2idx.classes_)), average=\"macro\")\n",
    "valid_loss = log_loss(y_valid, y_valid_prob)\n",
    "valid_acc = accuracy_score(y_valid, y_valid_pred)\n",
    "valid_f1 = f1_score(y_valid, y_valid_pred, labels=np.arange(len(label2idx.classes_)), average=\"macro\")\n",
    "print(f\"Train loss {train_loss:>8.3f}, accuracy {train_acc:>4.3f}, F1 {train_f1:>4.3f} \"\n",
    "      f\"| Valid loss {valid_loss:>8.3f}, accuracy {valid_acc:4.3f}, F1 {valid_f1:>4.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "11406bca-34af-4eac-8a3c-700df9e2762a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss    0.001, accuracy 1.000, F1 1.000\n"
     ]
    }
   ],
   "source": [
    "y_test_prob = model.predict_proba(X_test)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "test_loss = log_loss(y_test, y_test_prob)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, labels=np.arange(len(label2idx.classes_)), average=\"macro\")\n",
    "print(f\"Test loss {test_loss:>8.3f}, accuracy {test_acc:4.3f}, F1 {test_f1:>4.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6bc3dba6-d467-4fc9-9124-a5dbe816b65f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test != y_test_pred).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiobot",
   "language": "python",
   "name": "audiobot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
